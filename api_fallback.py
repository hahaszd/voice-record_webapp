"""
API Fallback Module for Speech-to-Text
ğŸ”¥ v112: å¤šè¯´è¯äººè½¬å½•ï¼ˆæ— æ ‡ç­¾æ¨¡å¼ï¼‰

ä¼˜å…ˆçº§ç­–ç•¥ï¼š
éº¦å…‹é£åœºæ™¯ï¼š
1. AI Builder Space (OpenAI Whisper) - å…è´¹ $100
2. OpenAI Whisper API - $0.006/min
3. Deepgram Nova-2 - $0.0077/min (å¤‡ç”¨)

ç³»ç»Ÿ/æ··åˆåœºæ™¯ï¼ˆå¤šè¯´è¯äººè¯†åˆ«ï¼‰ï¼š
1. OpenAI gpt-4o-transcribe-diarize - å¤šè¯´è¯äººè¯†åˆ«ï¼Œæ— æ ‡ç­¾
2. Google Cloud Speech-to-Text - $0.016/min + Diarizationï¼Œæ— æ ‡ç­¾
3. Deepgram Nova-2 - $0.0077/min (å¤‡ç”¨)

ğŸ¯ v112 æ–°ç‰¹æ€§:
- âœ… è½¬å½•æ‰€æœ‰è¯´è¯äººçš„è¯ï¼ˆåŒ…æ‹¬ YouTube è§†é¢‘ä¸­çš„å¤šäººå¯¹è¯ï¼‰
- âœ… ä¸æ˜¾ç¤º "Speaker A:", "Speaker B:" ç­‰æ ‡ç­¾
- âœ… è¿”å›å®Œæ•´çš„è¿ç»­æ–‡æœ¬
- âœ… ç¡®ä¿ä¸ä¼šä¸¢å¤±ä»»ä½•è¯´è¯äººçš„å†…å®¹
"""

import os
import time
import json
import base64
import requests
from typing import Tuple, Dict, Any, Optional
from logging_helper import TranscriptionLogger


def get_audio_content_type(filename: str) -> str:
    """æ ¹æ®æ–‡ä»¶åæ¨æ–­æ­£ç¡®çš„éŸ³é¢‘ MIME ç±»å‹"""
    name = (filename or '').lower()
    if name.endswith('.mp4') or name.endswith('.m4a'):
        return 'audio/mp4'
    elif name.endswith('.webm'):
        return 'audio/webm'
    elif name.endswith('.mp3'):
        return 'audio/mpeg'
    elif name.endswith('.flac'):
        return 'audio/flac'
    elif name.endswith('.wav'):
        return 'audio/wav'
    else:
        return 'audio/wav'


def detect_google_encoding(audio_content: bytes, filename: str) -> tuple:
    """
    æ ¹æ®éŸ³é¢‘å†…å®¹å’Œæ–‡ä»¶åæ£€æµ‹ Google STT æ‰€éœ€çš„ç¼–ç æ ¼å¼ã€‚
    è¿”å› (encoding, sample_rate_hertz)ï¼Œsample_rate_hertz ä¸º None æ—¶ä¸è®¾ç½®è¯¥å­—æ®µã€‚
    """
    # é€šè¿‡æ–‡ä»¶å¤´å­—èŠ‚æ£€æµ‹æ ¼å¼
    if len(audio_content) >= 12:
        if audio_content[:4] == b'RIFF' and audio_content[8:12] == b'WAVE':
            return ('LINEAR16', 48000)
        elif audio_content[:4] in (b'\x1aE\xdf\xa3', b'\x1a\x45\xdf\xa3'):
            return ('WEBM_OPUS', None)  # WEBM_OPUS ä¸éœ€è¦æŒ‡å®šé‡‡æ ·ç‡
    # fallbackï¼šæ ¹æ®æ–‡ä»¶ååˆ¤æ–­
    name = (filename or '').lower()
    if name.endswith('.webm'):
        return ('WEBM_OPUS', None)
    elif name.endswith('.mp3'):
        return ('MP3', None)
    return ('LINEAR16', 48000)

# ================================================================================
# å…¨å±€çŠ¶æ€ç®¡ç†ï¼ˆæœåŠ¡å™¨é‡å¯åé‡ç½®ï¼‰
# ================================================================================

API_FALLBACK_STATUS = {
    "ai_builder_quota_exceeded": False,
    "ai_builder_last_check": None,
    "openai_quota_exceeded": False,
    "openai_last_check": None,
    "deepgram_quota_exceeded": False,  # v111: Deepgram
    "deepgram_last_check": None,
    "last_successful_api": "ai_builder",  # v111: å›åˆ° AI Builder ä¸ºä¸»åŠ›
    "api_usage_count": {
        "ai_builder": 0,
        "openai": 0,
        "deepgram": 0,  # v111: Deepgram
        "google": 0,
        "openai_diarize": 0  # v111: OpenAI å¤šè¯´è¯äººæ¨¡å‹
    }
}

# æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡ä¸» API æ˜¯å¦æ¢å¤ï¼ˆç§’ï¼‰
QUOTA_RECHECK_INTERVAL = 3600  # 1 å°æ—¶


# ================================================================================
# é”™è¯¯æ£€æµ‹è¾…åŠ©å‡½æ•°
# ================================================================================

def is_quota_exceeded(status_code: Optional[int], error_message: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦æ˜¯ quota è€—å°½é”™è¯¯
    
    Args:
        status_code: HTTP çŠ¶æ€ç 
        error_message: é”™è¯¯ä¿¡æ¯
    
    Returns:
        bool: True è¡¨ç¤º quota è€—å°½
    """
    if not error_message:
        return False
    
    error_lower = str(error_message).lower()
    
    # å¸¸è§çš„ quota è€—å°½æŒ‡ç¤ºç¬¦
    quota_keywords = [
        "quota",
        "exceeded",
        "insufficient",
        "limit reached",
        "out of credits",
        "insufficient_quota",
        "rate_limit_exceeded",
        "billing",
        "payment required"
    ]
    
    # æ£€æŸ¥å…³é”®è¯
    has_quota_keyword = any(keyword in error_lower for keyword in quota_keywords)
    
    # æ£€æŸ¥ HTTP çŠ¶æ€ç 
    is_quota_status = status_code in [402, 429]  # 402: Payment Required, 429: Too Many Requests
    
    return has_quota_keyword or is_quota_status


def is_temporary_error(status_code: Optional[int], error_message: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦æ˜¯ä¸´æ—¶é”™è¯¯ï¼ˆå€¼å¾—é‡è¯•ï¼‰
    
    Args:
        status_code: HTTP çŠ¶æ€ç 
        error_message: é”™è¯¯ä¿¡æ¯
    
    Returns:
        bool: True è¡¨ç¤ºæ˜¯ä¸´æ—¶é”™è¯¯
    """
    if not error_message:
        return False
    
    error_lower = str(error_message).lower()
    
    # ä¸´æ—¶é”™è¯¯å…³é”®è¯
    temp_keywords = [
        "timeout",
        "connection",
        "network",
        "temporary",
        "unavailable",
        "try again"
    ]
    
    # æ£€æŸ¥å…³é”®è¯
    has_temp_keyword = any(keyword in error_lower for keyword in temp_keywords)
    
    # æ£€æŸ¥ HTTP çŠ¶æ€ç 
    is_temp_status = status_code in [500, 502, 503, 504]  # æœåŠ¡å™¨é”™è¯¯
    
    return has_temp_keyword or is_temp_status


def should_retry_api(api_name: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•æŸä¸ª API
    
    Args:
        api_name: API åç§° ("deepgram", "ai_builder", "openai")
    
    Returns:
        bool: True è¡¨ç¤ºåº”è¯¥é‡è¯•
    """
    # ğŸ†• v111: Deepgram
    if api_name == "deepgram":
        if API_FALLBACK_STATUS["deepgram_quota_exceeded"]:
            last_check = API_FALLBACK_STATUS["deepgram_last_check"]
            if last_check and (time.time() - last_check) < QUOTA_RECHECK_INTERVAL:
                return False
            print(f"[v111-FALLBACK] Deepgram quota æ£€æŸ¥é—´éš”å·²è¿‡ï¼Œå°è¯•é‡æ–°æ£€æµ‹")
            return True
        return True
    
    elif api_name == "ai_builder":
        # å¦‚æœæ ‡è®°ä¸º quota è€—å°½
        if API_FALLBACK_STATUS["ai_builder_quota_exceeded"]:
            # æ£€æŸ¥æ˜¯å¦è¿‡äº†é‡æ–°æ£€æŸ¥é—´éš”
            last_check = API_FALLBACK_STATUS["ai_builder_last_check"]
            if last_check and (time.time() - last_check) < QUOTA_RECHECK_INTERVAL:
                return False  # è¿˜æ²¡åˆ°é‡æ–°æ£€æŸ¥çš„æ—¶é—´
            # è¿‡äº†é—´éš”ï¼Œå¯ä»¥é‡è¯•ä¸€æ¬¡
            print(f"[FALLBACK] AI Builder Space quota æ£€æŸ¥é—´éš”å·²è¿‡ï¼Œå°è¯•é‡æ–°æ£€æµ‹")
            return True
        return True
    
    elif api_name == "openai":
        if API_FALLBACK_STATUS["openai_quota_exceeded"]:
            last_check = API_FALLBACK_STATUS["openai_last_check"]
            if last_check and (time.time() - last_check) < QUOTA_RECHECK_INTERVAL:
                return False
            print(f"[FALLBACK] OpenAI quota æ£€æŸ¥é—´éš”å·²è¿‡ï¼Œå°è¯•é‡æ–°æ£€æµ‹")
            return True
        return True
    
    return True


# ================================================================================
# ğŸ†• v111: API è°ƒç”¨å‡½æ•° - OpenAI gpt-4o-transcribe-diarize (å¤šè¯´è¯äºº)
# ================================================================================

async def _transcribe_openai_diarize(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, Dict[str, Any]]:
    """
    è°ƒç”¨ OpenAI gpt-4o-transcribe-diarize è¿›è¡Œå¤šè¯´è¯äººè½¬å½•
    
    ç‰¹ç‚¹ï¼š
    - åŸç”Ÿå¤šè¯´è¯äººè¯†åˆ«ï¼ˆSpeaker Diarizationï¼‰
    - æ”¯æŒä¸­è‹±æ–‡æ··åˆ
    - âœ… è¿”å›å®Œæ•´è½¬å½•æ–‡æœ¬ï¼ˆä¸åŒ…å«è¯´è¯äººæ ‡ç­¾ï¼‰
    - âœ… ç¡®ä¿æ‰€æœ‰è¯´è¯äººçš„è¯éƒ½è¢«è½¬å½•
    
    Args:
        audio_content: éŸ³é¢‘æ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹
        filename: éŸ³é¢‘æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    
    if not openai_api_key:
        raise Exception("OPENAI_API_KEY æœªé…ç½®")
    
    print(f"[v112-OPENAI-DIARIZE] ğŸ¤ å¼€å§‹è°ƒç”¨ OpenAI gpt-4o-transcribe-diarizeï¼ˆå¤šè¯´è¯äººè¯†åˆ«ï¼‰")
    print(f"[v112-OPENAI-DIARIZE] - æ–‡ä»¶å: {filename}")
    print(f"[v112-OPENAI-DIARIZE] - éŸ³é¢‘å¤§å°: {len(audio_content) / 1024:.2f} KB")
    if duration:
        print(f"[v112-OPENAI-DIARIZE] - æ—¶é•¿: {duration}ç§’")
    
    # OpenAI API endpoint
    api_url = "https://api.openai.com/v1/audio/transcriptions"
    
    # å‡†å¤‡è¯·æ±‚
    files = {
        'file': (filename, audio_content, get_audio_content_type(filename))
    }
    
    # ğŸ”¥ v112: ä½¿ç”¨ diarized_json æ ¼å¼ä»¥è·å–å®Œæ•´çš„å¤šè¯´è¯äººè½¬å½•
    # å‚è€ƒæ–‡æ¡£: https://platform.openai.com/docs/api-reference/audio/createTranscription
    data = {
        'model': 'gpt-4o-transcribe-diarize',
        'response_format': 'diarized_json',  # ğŸ”¥ ä½¿ç”¨ diarized_json è·å– segments
        'chunking_strategy': 'auto',  # è‡ªåŠ¨åˆ†æ®µï¼ˆéŸ³é¢‘>30ç§’æ—¶å¿…éœ€ï¼‰
    }
    
    # å¦‚æœæŒ‡å®šäº†è¯­è¨€ï¼Œæ·»åŠ è¯­è¨€å‚æ•°
    if language:
        data['language'] = language
        print(f"[v112-OPENAI-DIARIZE] æŒ‡å®šè¯­è¨€: {language}")
    else:
        print(f"[v112-OPENAI-DIARIZE] ğŸŒ ä½¿ç”¨è‡ªåŠ¨è¯­è¨€è¯†åˆ«")
    
    print(f"[v112-OPENAI-DIARIZE] ğŸ“¤ å‘é€è½¬å½•è¯·æ±‚ï¼ˆdiarized_json æ ¼å¼ï¼‰...")
    start_time = time.time()
    
    # å‘é€è¯·æ±‚
    response = requests.post(
        api_url,
        headers={
            "Authorization": f"Bearer {openai_api_key}"
        },
        files=files,
        data=data,
        timeout=300
    )
    
    api_time = time.time() - start_time
    print(f"[v112-OPENAI-DIARIZE] â±ï¸ API å“åº”è€—æ—¶: {api_time:.2f}ç§’")
    
    # æ£€æŸ¥å“åº”
    if response.status_code != 200:
        error_msg = f"OpenAI Diarize API é”™è¯¯ [{response.status_code}]: {response.text}"
        raise Exception(error_msg)
    
    # è§£æå“åº”
    result = response.json()
    
    # æå–è½¬å½•æ–‡æœ¬ï¼ˆæ ¹æ® diarized_json æ ¼å¼ï¼‰
    if 'segments' in result and result['segments']:
        print(f"[v112-OPENAI-DIARIZE] ğŸ¤ æ£€æµ‹åˆ°å¤šè¯´è¯äººä¿¡æ¯")
        
        # ç»Ÿè®¡è¯´è¯äººæ•°é‡
        speakers = set()
        for segment in result['segments']:
            if 'speaker' in segment:
                speakers.add(segment['speaker'])
        
        print(f"[v112-OPENAI-DIARIZE] - æ£€æµ‹åˆ° {len(speakers)} ä¸ªè¯´è¯äºº")
        
        # ğŸ”¥ v112: åˆå¹¶æ‰€æœ‰è¯´è¯äººçš„æ–‡æœ¬ï¼Œä¸åŒ…å«è¯´è¯äººæ ‡ç­¾
        # æŒ‰æ—¶é—´é¡ºåºæ‹¼æ¥æ‰€æœ‰ segment çš„æ–‡æœ¬
        all_texts = []
        for segment in result['segments']:
            text = segment.get('text', '').strip()
            if text:  # åªæ·»åŠ éç©ºæ–‡æœ¬
                all_texts.append(text)
        
        # åˆå¹¶ä¸ºä¸€æ®µå®Œæ•´æ–‡æœ¬
        transcription_text = " ".join(all_texts)
        print(f"[v112-OPENAI-DIARIZE] âœ… å·²åˆå¹¶æ‰€æœ‰è¯´è¯äººæ–‡æœ¬ï¼ˆæ— æ ‡ç­¾ï¼‰")
        print(f"[v112-OPENAI-DIARIZE] - {len(speakers)} ä¸ªè¯´è¯äººçš„ {len(all_texts)} ä¸ªè¯­å¥ç‰‡æ®µ")
        
        metadata = {
            "api": "openai_diarize",
            "model": "gpt-4o-transcribe-diarize",
            "num_speakers": len(speakers),
            "num_segments": len(result['segments']),
            "api_response_time": round(api_time, 2),
            "status_code": response.status_code,
            "note": "All speakers transcribed without labels"
        }
    else:
        # æ²¡æœ‰ segmentsï¼Œä½¿ç”¨æ™®é€šæ–‡æœ¬ï¼ˆfallbackï¼‰
        transcription_text = result.get('text', '')
        if not transcription_text:
            raise Exception("OpenAI Diarize API è¿”å›ç©ºæ–‡æœ¬")
        
        print(f"[v112-OPENAI-DIARIZE] âš ï¸ æœªæ£€æµ‹åˆ° segmentsï¼Œä½¿ç”¨å®Œæ•´æ–‡æœ¬")
        
        metadata = {
            "api": "openai_diarize",
            "model": "gpt-4o-transcribe-diarize",
            "api_response_time": round(api_time, 2),
            "status_code": response.status_code
        }
    
    print(f"[v112-OPENAI-DIARIZE] âœ… è½¬å½•æˆåŠŸ")
    print(f"[v112-OPENAI-DIARIZE] - æ–‡æœ¬é•¿åº¦: {len(transcription_text)} å­—ç¬¦")
    
    # è®°å½•æ—¥å¿—
    if logger:
        logger.log_api_response(
            status_code=200,
            response_headers={},
            response_body={"text": transcription_text, "metadata": metadata},
            duration_seconds=api_time
        )
    
    # æ›´æ–°å…¨å±€çŠ¶æ€
    API_FALLBACK_STATUS["api_usage_count"]["openai_diarize"] += 1
    API_FALLBACK_STATUS["last_successful_api"] = "openai_diarize"
    
    return transcription_text, metadata


# ================================================================================
# ğŸ†• v111: API è°ƒç”¨å‡½æ•° - Deepgram Nova-2 (å¤‡ç”¨)
# ================================================================================

async def _transcribe_deepgram(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    enable_diarization: bool = False,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, Dict[str, Any]]:
    """
    è°ƒç”¨ Deepgram Nova-3 Multilingual API è¿›è¡Œè½¬å½•
    
    ç‰¹ç‚¹ï¼š
    - å¤šè¯­è¨€æ”¯æŒï¼ˆ90+ è¯­è¨€ï¼‰
    - å¯é€‰å¤šè¯´è¯äººè¯†åˆ«ï¼ˆDiarizationï¼‰
    - é«˜å‡†ç¡®ç‡ï¼ˆæœ€æ–° Nova-3 æ¨¡å‹ï¼‰
    - å¿«é€Ÿå“åº”
    
    Args:
        audio_content: éŸ³é¢‘æ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹
        filename: éŸ³é¢‘æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼ŒDeepgram æ”¯æŒè‡ªåŠ¨æ£€æµ‹ï¼‰
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        enable_diarization: æ˜¯å¦å¯ç”¨å¤šè¯´è¯äººè¯†åˆ«
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    print(f"[v111-DEEPGRAM-DEBUG] ========== è¿›å…¥ _transcribe_deepgram å‡½æ•° ==========")
    
    from server2 import DEEPGRAM_API_KEY
    
    print(f"[v111-DEEPGRAM-DEBUG] DEEPGRAM_API_KEY å­˜åœ¨: {bool(DEEPGRAM_API_KEY)}")
    print(f"[v111-DEEPGRAM-DEBUG] DEEPGRAM_API_KEY é•¿åº¦: {len(DEEPGRAM_API_KEY) if DEEPGRAM_API_KEY else 0}")
    
    if not DEEPGRAM_API_KEY:
        raise Exception("DEEPGRAM_API_KEY æœªé…ç½®")
    
    try:
        print(f"[v111-DEEPGRAM-DEBUG] ä½¿ç”¨ REST API ç›´æ¥è°ƒç”¨ Deepgram")
        
        print(f"[v111-DEEPGRAM] ğŸš€ å¼€å§‹è°ƒç”¨ Deepgram Nova-3 Multilingual API")
        print(f"[v111-DEEPGRAM] - æ–‡ä»¶å: {filename}")
        print(f"[v111-DEEPGRAM] - éŸ³é¢‘å¤§å°: {len(audio_content) / 1024:.2f} KB")
        if duration:
            print(f"[v111-DEEPGRAM] - æ—¶é•¿: {duration}ç§’")
        print(f"[v111-DEEPGRAM] - å¤šè¯´è¯äººè¯†åˆ«: {'å¯ç”¨' if enable_diarization else 'ç¦ç”¨'}")
        
        # ä½¿ç”¨ REST API ç›´æ¥è°ƒç”¨
        api_url = "https://api.deepgram.com/v1/listen"
        
        # ğŸŒ ä½¿ç”¨ Nova-2 æ”¯æŒè‡ªåŠ¨è¯­è¨€è¯†åˆ«æˆ–æŒ‡å®šè¯­è¨€
        # Nova-2 æ”¯æŒå¤šç§è¯­è¨€ï¼Œå¯ä»¥è‡ªåŠ¨æ£€æµ‹æˆ–æŒ‡å®šè¯­è¨€ä»£ç 
        params = {
            "model": "nova-2",
            "smart_format": "true",
            "punctuate": "true",
            "paragraphs": "true",
        }
        
        # ğŸ”¥ v113: æ”¯æŒè‡ªåŠ¨è¯­è¨€è¯†åˆ«
        if language:
            # ç”¨æˆ·æŒ‡å®šäº†è¯­è¨€ï¼Œä½¿ç”¨æŒ‡å®šè¯­è¨€
            params["language"] = language
            print(f"[v113-DEEPGRAM] æŒ‡å®šè¯­è¨€: {language}")
        else:
            # ä¸æŒ‡å®šè¯­è¨€ï¼Œè®©Deepgramè‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰
            # Deepgram Nova-2 æ”¯æŒè‡ªåŠ¨è¯­è¨€æ£€æµ‹
            print(f"[v113-DEEPGRAM] ğŸŒ ä½¿ç”¨è‡ªåŠ¨è¯­è¨€è¯†åˆ«")
        
        if enable_diarization:
            params["diarize"] = "true"
        
        headers = {
            "Authorization": f"Token {DEEPGRAM_API_KEY}",
            "Content-Type": "audio/wav"
        }
        
        print(f"[v111-DEEPGRAM] ğŸ“¤ å‘é€è½¬å½•è¯·æ±‚...")
        start_time = time.time()
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            api_url,
            headers=headers,
            params=params,
            data=audio_content,
            timeout=300
        )
        
        api_time = time.time() - start_time
        print(f"[v111-DEEPGRAM] â±ï¸ API å“åº”è€—æ—¶: {api_time:.2f}ç§’")
        
        if response.status_code != 200:
            error_msg = f"Deepgram API é”™è¯¯ [{response.status_code}]: {response.text}"
            raise Exception(error_msg)
        
        # è§£æå“åº”
        result = response.json()
        
        # æå–è½¬å½•æ–‡æœ¬
        try:
            transcription_text = result['results']['channels'][0]['alternatives'][0]['transcript']
        except (KeyError, IndexError) as e:
            raise Exception(f"æ— æ³•è§£æ Deepgram å“åº”: {e}")
        
        if not transcription_text or not transcription_text.strip():
            raise Exception("Deepgram è¿”å›ç©ºè½¬å½•ç»“æœ")
        
        print(f"[v111-DEEPGRAM] âœ… è½¬å½•æˆåŠŸ")
        print(f"[v111-DEEPGRAM] - æ–‡æœ¬é•¿åº¦: {len(transcription_text)} å­—ç¬¦")
        
        # æå–å…ƒæ•°æ®
        metadata = {
            "api": "deepgram_nova2_chinese",
            "model": "nova-2",
            "language": "zh-CN",
            "api_response_time": round(api_time, 2),
            "audio_duration": duration,
            "diarization_enabled": enable_diarization,
        }
        
        # å¦‚æœå¯ç”¨äº†å¤šè¯´è¯äººè¯†åˆ«ï¼Œå¤„ç†è¯´è¯äººæ ‡ç­¾
        if enable_diarization:
            try:
                words = result['results']['channels'][0]['alternatives'][0].get('words', [])
                if words:
                    print(f"[v111-DEEPGRAM] ğŸ¤ æ£€æµ‹åˆ°å¤šè¯´è¯äººä¿¡æ¯")
                    speakers = set()
                    for word in words:
                        if 'speaker' in word:
                            speakers.add(word['speaker'])
                    
                    if len(speakers) > 1:
                        print(f"[v111-DEEPGRAM] - æ£€æµ‹åˆ° {len(speakers)} ä¸ªè¯´è¯äºº")
                        metadata["num_speakers"] = len(speakers)
                        
                        # æ ¼å¼åŒ–å¸¦è¯´è¯äººæ ‡ç­¾çš„æ–‡æœ¬
                        formatted_text = []
                        current_speaker = None
                        current_text = []
                        
                        for word in words:
                            word_speaker = word.get('speaker')
                            word_text = word.get('punctuated_word', word.get('word', ''))
                            
                            if current_speaker is None:
                                current_speaker = word_speaker
                            elif word_speaker != current_speaker:
                                # åˆ‡æ¢è¯´è¯äºº
                                if current_text:
                                    formatted_text.append(f"Speaker {current_speaker}: {' '.join(current_text)}")
                                current_speaker = word_speaker
                                current_text = []
                            
                            current_text.append(word_text)
                        
                        # æ·»åŠ æœ€åä¸€ä¸ªè¯´è¯äººçš„æ–‡æœ¬
                        if current_text:
                            formatted_text.append(f"Speaker {current_speaker}: {' '.join(current_text)}")
                        
                        if formatted_text:
                            transcription_text = "\n".join(formatted_text)
                            print(f"[v111-DEEPGRAM] âœ… å·²æ ¼å¼åŒ–å¤šè¯´è¯äººæ–‡æœ¬")
            except Exception as e:
                print(f"[v111-DEEPGRAM] âš ï¸ å¤šè¯´è¯äººå¤„ç†å¤±è´¥: {e}")
        
        # è®°å½•æ—¥å¿—
        if logger:
            logger.log_api_response(
                status_code=200,
                response_headers={},
                response_body={"text": transcription_text, "metadata": metadata},
                duration_seconds=api_time
            )
        
        # æ›´æ–°å…¨å±€çŠ¶æ€
        API_FALLBACK_STATUS["api_usage_count"]["deepgram"] += 1
        API_FALLBACK_STATUS["last_successful_api"] = "deepgram"
        
        return transcription_text, metadata
        
    except Exception as e:
        error_msg = str(e)
        print(f"[v111-DEEPGRAM] âŒ Deepgram API è°ƒç”¨å¤±è´¥: {error_msg}")
        
        # è®°å½•å¤±è´¥æ—¥å¿—
        if logger:
            logger.log_error(
                error_type="DEEPGRAM_API_ERROR",
                error_message=error_msg
            )
        
        raise Exception(f"Deepgram API è½¬å½•å¤±è´¥: {error_msg}")


# ================================================================================
# API è°ƒç”¨å‡½æ•° - AI Builder Space
# ================================================================================

async def _transcribe_ai_builder(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, Dict[str, Any]]:
    """
    è°ƒç”¨ AI Builder Space API è¿›è¡Œè½¬å½•
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    from server2 import AI_BUILDER_TOKEN, AI_BUILDER_API_BASE
    
    print(f"[v111-AI-BUILDER-DEBUG] ========== è¿›å…¥ _transcribe_ai_builder å‡½æ•° ==========")
    print(f"[v111-AI-BUILDER-DEBUG] AI_BUILDER_TOKEN å­˜åœ¨: {bool(AI_BUILDER_TOKEN)}")
    print(f"[v111-AI-BUILDER-DEBUG] audio_content ç±»å‹: {type(audio_content)}")
    print(f"[v111-AI-BUILDER-DEBUG] audio_content æ˜¯å¦ä¸º None: {audio_content is None}")
    if audio_content:
        print(f"[v111-AI-BUILDER-DEBUG] audio_content é•¿åº¦: {len(audio_content)}")
    else:
        print(f"[v111-AI-BUILDER-DEBUG] âŒâŒâŒ audio_content æ˜¯ Noneï¼è¿™æ˜¯é”™è¯¯çš„æ ¹æºï¼")
        raise Exception("audio_content æ˜¯ Noneï¼Œæ— æ³•è¿›è¡Œè½¬å½•")
    
    if not AI_BUILDER_TOKEN:
        raise Exception("AI_BUILDER_TOKEN æœªé…ç½®")
    
    print(f"[FALLBACK] å°è¯•ä½¿ç”¨ AI Builder Space API")
    print(f"[v109-FIX] ğŸ”§ æ·»åŠ  Prompt å‚æ•°ï¼Œå°è¯•è§£å†³å†…å®¹æˆªæ–­é—®é¢˜")
    print(f"[v109-FIX] ğŸ”§ è¶…æ—¶å¢åŠ åˆ° 300 ç§’ï¼Œresponse_format æ”¹ä¸º verbose_json")
    
    # å‡†å¤‡è¯·æ±‚
    api_url = f"{AI_BUILDER_API_BASE}/audio/transcriptions"
    
    # ğŸ”¥ AI Builder Space ä½¿ç”¨ 'audio_file' ä½œä¸ºå­—æ®µåï¼ˆä¸æ˜¯ 'file'ï¼‰
    files = {
        'audio_file': (filename, audio_content, get_audio_content_type(filename))
    }
    
    # ğŸ”§ v109: æ·»åŠ  prompt å‚æ•°ï¼Œè§£å†³å†…å®¹æˆªæ–­é—®é¢˜
    # ğŸŒ v110: æ¢å¤è‡ªåŠ¨è¯­è¨€è¯†åˆ«ï¼ˆç§»é™¤ v108-TEST å¼ºåˆ¶è‹±æ–‡ï¼‰
    form_data = {
        'model': 'whisper-1',
        'response_format': 'verbose_json',  # v109: æ”¹ä¸º verbose è·å–æ›´å¤šä¿¡æ¯
        'prompt': 'This is a continuous recording containing both human speech and video/audio playback (such as YouTube). Please transcribe all audio content completely and accurately, including all speech, video audio, and background sounds throughout the entire recording.'  # v109: å¼•å¯¼å®Œæ•´è½¬å½•
    }
    
    # ğŸŒ v110: å¦‚æœæŒ‡å®šäº†è¯­è¨€ï¼Œåˆ™ä½¿ç”¨æŒ‡å®šè¯­è¨€ï¼›å¦åˆ™è‡ªåŠ¨æ£€æµ‹
    if language:
        form_data['language'] = language
        print(f"[v110-WHISPER] æŒ‡å®šè¯­è¨€: {language}")
    else:
        print(f"[v110-WHISPER] ğŸŒ ä½¿ç”¨è‡ªåŠ¨è¯­è¨€è¯†åˆ«")
    
    # å‘é€è¯·æ±‚
    response = requests.post(
        api_url,
        headers={
            "Authorization": f"Bearer {AI_BUILDER_TOKEN}",
            "Accept": "application/json"
        },
        files=files,
        data=form_data,
        timeout=300  # v109: å¢åŠ è¶…æ—¶åˆ° 5 åˆ†é’Ÿï¼Œé¿å…é•¿éŸ³é¢‘è¢«æˆªæ–­
    )
    
    # æ£€æŸ¥å“åº”
    if response.status_code != 200:
        error_msg = f"AI Builder Space API é”™è¯¯ [{response.status_code}]: {response.text}"
        raise Exception(error_msg)
    
    # è§£æå“åº” - å…ˆè®°å½•åŸå§‹å“åº”ä¾¿äºè°ƒè¯•
    raw_text = response.text
    print(f"[AI-BUILDER-RAW] åŸå§‹å“åº”å‰200å­—ç¬¦: {repr(raw_text[:200])}")
    
    result = response.json()
    print(f"[AI-BUILDER-RAW] JSONè§£æåç±»å‹: {type(result)}, å€¼: {repr(str(result)[:200])}")
    
    # v109: æ”¯æŒå¤šç§å“åº”æ ¼å¼ï¼Œå…¼å®¹ä¸åŒ key åç§°
    if isinstance(result, dict) and 'text' in result:
        text = result.get('text', '')
    elif isinstance(result, dict) and 'query' in result:
        text = result.get('query', '')
    elif isinstance(result, str):
        text = result
    else:
        text = str(result)
    
    # æ¸…ç†æ–‡æœ¬ï¼šå»é™¤é¦–å°¾å¼•å·ã€\nè½¬ä¹‰ç¬¦å·ç­‰æ ¼å¼æ®‹ç•™
    text = text.strip()
    # å»é™¤é¦–å°¾çš„å¼•å·ï¼ˆå¦‚æœæ•´ä¸ªå­—ç¬¦ä¸²è¢«å¼•å·åŒ…è£¹ï¼‰
    if text.startswith('"') and text.endswith('"') and len(text) > 2:
        text = text[1:-1]
    elif text.startswith('"') and '"}' in text:
        # å¤„ç†å¦‚ "\n\ntext"} çš„æ ¼å¼
        text = text.lstrip('"').rstrip('}"').strip()
    # å»é™¤å¼€å¤´çš„ \n è½¬ä¹‰å­—ç¬¦ï¼ˆå­—é¢é‡ backslash-nï¼‰
    text = text.lstrip('\\n').strip()
    # å»é™¤å¼€å¤´çš„å®é™…æ¢è¡Œç¬¦
    text = text.lstrip('\n').strip()
    
    print(f"[AI-BUILDER-CLEANED] æ¸…ç†åæ–‡æœ¬å‰100å­—ç¬¦: {repr(text[:100])}")
    
    if not text:
        raise Exception("AI Builder Space API è¿”å›ç©ºæ–‡æœ¬")
    
    # v109: è®°å½• verbose ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'segments' in result and result['segments'] is not None:
        segments_count = len(result['segments'])
        print(f"[v109-DEBUG] è½¬å½•åŒ…å« {segments_count} ä¸ªéŸ³é¢‘æ®µè½")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ®µè½è¢«æ ‡è®°ä¸º"éè¯­éŸ³"
        for i, seg in enumerate(result['segments']):
            no_speech_prob = seg.get('no_speech_prob', 0)
            if no_speech_prob > 0.5:
                print(f"[v109-WARNING] æ®µè½ {i} è¢«åˆ¤æ–­ä¸ºéè¯­éŸ³ (æ¦‚ç‡: {no_speech_prob:.2f})")
    
    metadata = {
        "api": "ai_builder",
        "model": "whisper-1",
        "status_code": response.status_code
    }
    
    return text, metadata


# ================================================================================
# API è°ƒç”¨å‡½æ•° - OpenAI Whisper
# ================================================================================

async def _transcribe_openai(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,  # ğŸ†• v111: æ·»åŠ  duration å‚æ•°
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, Dict[str, Any]]:
    """
    ç›´æ¥è°ƒç”¨ OpenAI Whisper API è¿›è¡Œè½¬å½•
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    
    if not openai_api_key:
        raise Exception("OPENAI_API_KEY æœªé…ç½®")
    
    print(f"[FALLBACK] å°è¯•ä½¿ç”¨ OpenAI Whisper API")
    print(f"[v109-FIX] ğŸ”§ æ·»åŠ  Prompt å‚æ•°ï¼Œå°è¯•è§£å†³å†…å®¹æˆªæ–­é—®é¢˜")
    
    # OpenAI API endpoint
    api_url = "https://api.openai.com/v1/audio/transcriptions"
    
    # å‡†å¤‡è¯·æ±‚
    files = {
        'file': (filename, audio_content, get_audio_content_type(filename))
    }
    
    # ğŸ”§ v109: æ·»åŠ  prompt å‚æ•°
    # ğŸŒ v110: æ¢å¤è‡ªåŠ¨è¯­è¨€è¯†åˆ«ï¼ˆç§»é™¤ v108-TEST å¼ºåˆ¶è‹±æ–‡ï¼‰
    data = {
        'model': 'whisper-1',
        'response_format': 'verbose_json',  # v109: æ”¹ä¸º verbose
        'prompt': 'This is a continuous recording containing both human speech and video/audio playback (such as YouTube). Please transcribe all audio content completely and accurately, including all speech, video audio, and background sounds throughout the entire recording.'  # v109: å¼•å¯¼å®Œæ•´è½¬å½•
    }
    
    # ğŸŒ v110: å¦‚æœæŒ‡å®šäº†è¯­è¨€ï¼Œåˆ™ä½¿ç”¨æŒ‡å®šè¯­è¨€ï¼›å¦åˆ™è‡ªåŠ¨æ£€æµ‹
    if language:
        data['language'] = language
        print(f"[v110-WHISPER] æŒ‡å®šè¯­è¨€: {language}")
    else:
        print(f"[v110-WHISPER] ğŸŒ ä½¿ç”¨è‡ªåŠ¨è¯­è¨€è¯†åˆ«")
    
    # å‘é€è¯·æ±‚
    response = requests.post(
        api_url,
        headers={
            "Authorization": f"Bearer {openai_api_key}"
        },
        files=files,
        data=data,
        timeout=300  # v109: å¢åŠ è¶…æ—¶åˆ° 5 åˆ†é’Ÿ
    )
    
    # æ£€æŸ¥å“åº”
    if response.status_code != 200:
        error_msg = f"OpenAI API é”™è¯¯ [{response.status_code}]: {response.text}"
        raise Exception(error_msg)
    
    # è§£æå“åº”
    result = response.json()
    
    # v109: æ”¯æŒ verbose_json æ ¼å¼
    if isinstance(result, dict) and 'text' in result:
        text = result.get('text', '')
    else:
        text = result if isinstance(result, str) else str(result)
    
    if not text:
        raise Exception("OpenAI API è¿”å›ç©ºæ–‡æœ¬")
    
    # v109: è®°å½• verbose ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'segments' in result and result['segments'] is not None:
        segments_count = len(result['segments'])
        print(f"[v109-DEBUG] OpenAI è½¬å½•åŒ…å« {segments_count} ä¸ªéŸ³é¢‘æ®µè½")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ®µè½è¢«æ ‡è®°ä¸º"éè¯­éŸ³"
        for i, seg in enumerate(result['segments']):
            no_speech_prob = seg.get('no_speech_prob', 0)
            if no_speech_prob > 0.5:
                start = seg.get('start', 0)
                end = seg.get('end', 0)
                print(f"[v109-WARNING] æ®µè½ {i} ({start:.1f}s-{end:.1f}s) è¢«åˆ¤æ–­ä¸ºéè¯­éŸ³ (æ¦‚ç‡: {no_speech_prob:.2f})")
    
    metadata = {
        "api": "openai",
        "model": "whisper-1",
        "status_code": response.status_code
    }
    
    return text, metadata


# ================================================================================
# API è°ƒç”¨å‡½æ•° - Google Cloud Speech-to-Text
# ================================================================================

def convert_language_code_for_google(lang_code: str) -> str:
    """
    å°†æ ‡å‡†è¯­è¨€ä»£ç è½¬æ¢ä¸º Google Cloud Speech-to-Text æ ¼å¼
    
    Args:
        lang_code: æ ‡å‡†è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en', 'zh'ï¼‰
    
    Returns:
        str: Google æ ¼å¼çš„è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en-US', 'zh-CN'ï¼‰
    """
    # å¸¸è§è¯­è¨€æ˜ å°„
    google_lang_map = {
        'en': 'en-US',
        'zh': 'zh-CN',
        'es': 'es-ES',
        'fr': 'fr-FR',
        'de': 'de-DE',
        'ja': 'ja-JP',
        'ko': 'ko-KR',
        'pt': 'pt-BR',
        'ru': 'ru-RU',
        'ar': 'ar-SA',
        'it': 'it-IT',
        'nl': 'nl-NL',
        'tr': 'tr-TR',
        'pl': 'pl-PL',
        'sv': 'sv-SE',
        'da': 'da-DK',
        'fi': 'fi-FI',
        'no': 'no-NO',
        'cs': 'cs-CZ',
        'el': 'el-GR',
        'he': 'he-IL',
        'hi': 'hi-IN',
        'id': 'id-ID',
        'ms': 'ms-MY',
        'th': 'th-TH',
        'vi': 'vi-VN',
        'uk': 'uk-UA',
        'ro': 'ro-RO',
        'sk': 'sk-SK',
        'bg': 'bg-BG',
        'hr': 'hr-HR',
        'sr': 'sr-RS',
        'ca': 'ca-ES',
        'hu': 'hu-HU',
        'lt': 'lt-LT',
        'lv': 'lv-LV',
        'et': 'et-EE',
        'sl': 'sl-SI',
    }
    
    # å¦‚æœå·²ç»æ˜¯æ­£ç¡®æ ¼å¼ï¼ˆå¦‚ 'en-US'ï¼‰ï¼Œç›´æ¥è¿”å›
    if '-' in lang_code:
        return lang_code
    
    # æŸ¥æ‰¾æ˜ å°„
    return google_lang_map.get(lang_code, f'{lang_code}-{lang_code.upper()}')


# ================================================================================
# ğŸ™ï¸ v110: å¤šè¯´è¯äººåˆ†ç¦»è¾…åŠ©å‡½æ•°
# ================================================================================

def count_unique_speakers(result: Dict[str, Any]) -> int:
    """
    ç»Ÿè®¡æ£€æµ‹åˆ°çš„è¯´è¯äººæ•°é‡
    
    Args:
        result: Google API è¿”å›çš„ç»“æœ
    
    Returns:
        int: è¯´è¯äººæ•°é‡
    """
    speakers = set()
    
    if "results" in result:
        for r in result["results"]:
            if "alternatives" in r and len(r["alternatives"]) > 0:
                words = r["alternatives"][0].get("words", [])
                for word in words:
                    speaker_tag = word.get("speakerTag")
                    if speaker_tag:
                        speakers.add(speaker_tag)
    
    return len(speakers)


def parse_diarization_result(result: Dict[str, Any], remove_speaker_labels: bool = False) -> str:
    """
    è§£æå¤šè¯´è¯äººåˆ†ç¦»ç»“æœï¼Œæ ¼å¼åŒ–è¾“å‡º
    
    Args:
        result: Google API è¿”å›çš„ç»“æœ
        remove_speaker_labels: æ˜¯å¦ç§»é™¤è¯´è¯äººæ ‡ç­¾ï¼ˆTrue = åªè¿”å›æ–‡æœ¬ï¼ŒFalse = åŒ…å«æ ‡ç­¾ï¼‰
    
    Returns:
        str: æ ¼å¼åŒ–çš„è½¬å½•æ–‡æœ¬
    """
    # æ”¶é›†æ‰€æœ‰ words åŠå…¶ speaker tag
    all_words = []
    
    if "results" in result:
        for r in result["results"]:
            if "alternatives" in r and len(r["alternatives"]) > 0:
                words = r["alternatives"][0].get("words", [])
                for word in words:
                    all_words.append({
                        "word": word.get("word", ""),
                        "speaker": word.get("speakerTag", 0),
                        "startTime": word.get("startTime", "0s"),
                        "endTime": word.get("endTime", "0s")
                    })
    
    if not all_words:
        # å¦‚æœæ²¡æœ‰ word-level æ•°æ®ï¼Œé€€å›åˆ°æ ‡å‡†æ ¼å¼
        text = ""
        if "results" in result:
            for r in result["results"]:
                if "alternatives" in r and len(r["alternatives"]) > 0:
                    text += r["alternatives"][0].get("transcript", "")
        return text
    
    # ğŸ”¥ v112: å¦‚æœåªéœ€è¦å®Œæ•´æ–‡æœ¬ï¼ˆä¸éœ€è¦æ ‡ç­¾ï¼‰ï¼Œç›´æ¥æ‹¼æ¥æ‰€æœ‰å•è¯
    if remove_speaker_labels:
        all_text = " ".join([word_info["word"] for word_info in all_words])
        return all_text
    
    # ä»¥ä¸‹æ˜¯åŸæœ‰çš„å¸¦æ ‡ç­¾é€»è¾‘
    # æŒ‰è¯´è¯äººåˆ†ç»„
    current_speaker = None
    segments = []
    current_segment = []
    
    for word_info in all_words:
        speaker = word_info["speaker"]
        word = word_info["word"]
        
        if speaker != current_speaker:
            # è¯´è¯äººåˆ‡æ¢
            if current_segment:
                segments.append({
                    "speaker": current_speaker,
                    "text": " ".join(current_segment)
                })
            current_speaker = speaker
            current_segment = [word]
        else:
            current_segment.append(word)
    
    # æ·»åŠ æœ€åä¸€ä¸ª segment
    if current_segment:
        segments.append({
            "speaker": current_speaker,
            "text": " ".join(current_segment)
        })
    
    # æ ¼å¼åŒ–è¾“å‡º
    if len(segments) == 1:
        # åªæœ‰ä¸€ä¸ªè¯´è¯äººï¼Œç›´æ¥è¿”å›æ–‡æœ¬ï¼ˆä¸æ·»åŠ æ ‡ç­¾ï¼‰
        return segments[0]["text"]
    else:
        # å¤šä¸ªè¯´è¯äººï¼Œæ·»åŠ æ ‡ç­¾
        formatted_lines = []
        for seg in segments:
            formatted_lines.append(f"Speaker {seg['speaker']}: {seg['text']}")
        return "\n".join(formatted_lines)


async def _transcribe_google(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    logger: Optional[TranscriptionLogger] = None,
    enable_diarization: bool = False,  # ğŸ™ï¸ v110: æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»
    remove_speaker_labels: bool = False  # ğŸ”¥ v112: æ˜¯å¦ç§»é™¤è¯´è¯äººæ ‡ç­¾
) -> Tuple[str, Dict[str, Any]]:
    """
    è°ƒç”¨ Google Cloud Speech-to-Text API è¿›è¡Œè½¬å½•
    ğŸ™ï¸ v110: æ”¯æŒå¤šè¯´è¯äººåˆ†ç¦»ï¼ˆSpeaker Diarizationï¼‰
    ğŸ”¥ v112: æ”¯æŒç§»é™¤è¯´è¯äººæ ‡ç­¾ï¼ˆè½¬å½•æ‰€æœ‰äººä½†ä¸æ˜¾ç¤ºæ ‡ç­¾ï¼‰
    
    Args:
        audio_content: éŸ³é¢‘å†…å®¹
        filename: æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨è¯†åˆ«ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨
        enable_diarization: æ˜¯å¦å¯ç”¨å¤šè¯´è¯äººåˆ†ç¦»
        remove_speaker_labels: æ˜¯å¦ç§»é™¤è¯´è¯äººæ ‡ç­¾ï¼ˆTrue = åªè¿”å›å®Œæ•´æ–‡æœ¬ï¼‰
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    from server2 import get_access_token, get_project_id
    
    print(f"[FALLBACK] å°è¯•ä½¿ç”¨ Google Cloud Speech-to-Text API")
    if enable_diarization:
        print(f"[v112-GOOGLE-DIARIZATION] ğŸ™ï¸ å¯ç”¨å¤šè¯´è¯äººåˆ†ç¦»ï¼ˆSpeaker Diarizationï¼‰")
        if remove_speaker_labels:
            print(f"[v112-GOOGLE-DIARIZATION] âœ… æ¨¡å¼: è½¬å½•æ‰€æœ‰è¯´è¯äººï¼Œä½†ä¸æ˜¾ç¤ºæ ‡ç­¾")
        else:
            print(f"[v112-GOOGLE-DIARIZATION] ğŸ“‹ æ¨¡å¼: è½¬å½•æ‰€æœ‰è¯´è¯äººå¹¶æ˜¾ç¤ºæ ‡ç­¾")
    
    # è·å–è®¿é—®ä»¤ç‰Œå’Œé¡¹ç›® ID
    access_token = get_access_token()
    project_id = get_project_id()
    
    # Google API endpoint
    api_url = f"https://speech.googleapis.com/v1/speech:recognize"
    
    # ç¼–ç éŸ³é¢‘
    audio_base64 = base64.b64encode(audio_content).decode('utf-8')
    
    # è‡ªåŠ¨æ£€æµ‹ç¼–ç æ ¼å¼ï¼ˆæ”¯æŒ WAV/LINEAR16 å’Œ WebM/WEBM_OPUSï¼‰
    google_encoding, sample_rate = detect_google_encoding(audio_content, filename)
    print(f"[GOOGLE-STT] æ£€æµ‹åˆ°ç¼–ç æ ¼å¼: {google_encoding}" + (f", é‡‡æ ·ç‡: {sample_rate}Hz" if sample_rate else "ï¼ˆé‡‡æ ·ç‡è‡ªåŠ¨æ£€æµ‹ï¼‰"))
    
    # æ„å»ºåŸºç¡€é…ç½®
    config = {
        "encoding": google_encoding,
        "enableAutomaticPunctuation": True,
        "model": "default"
    }
    if sample_rate:
        config["sampleRateHertz"] = sample_rate
    
    # ğŸŒ è¯­è¨€è®¾ç½®ï¼ˆæ”¯æŒè‹±æ–‡+ä¸­æ–‡åŒè¯­è‡ªåŠ¨æ£€æµ‹ï¼‰
    if language:
        # ç”¨æˆ·æŒ‡å®šäº†è¯­è¨€
        config["languageCode"] = convert_language_code_for_google(language)
        print(f"[v112-GOOGLE] æŒ‡å®šè¯­è¨€: {config['languageCode']}")
    else:
        # é»˜è®¤ä½¿ç”¨è‹±æ–‡+ä¸­æ–‡åŒè¯­æ”¯æŒï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
        config["languageCode"] = "en-US"  # ä¸»è¦è¯­è¨€
        config["alternativeLanguageCodes"] = ["zh-CN"]  # å¤‡é€‰ä¸­æ–‡
        print(f"[v112-GOOGLE] ğŸŒ åŒè¯­æ¨¡å¼: ä¸»è¯­è¨€ en-US, å¤‡é€‰ zh-CNï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰")
    
    # ğŸ™ï¸ v110/v112: æ·»åŠ å¤šè¯´è¯äººåˆ†ç¦»é…ç½®
    # å‚è€ƒæ–‡æ¡£: https://cloud.google.com/speech-to-text/v2/docs/multiple-voices
    # ğŸ”¥ v112: ä¼˜åŒ–ä¸º maxSpeakers=6ï¼ˆYouTube è§†é¢‘å¾ˆå°‘è¶…è¿‡ 6 äººï¼Œæ›´å‡†ç¡®ï¼‰
    if enable_diarization:
        config["diarizationConfig"] = {
            "enableSpeakerDiarization": True,
            "minSpeakerCount": 1,  # æœ€å°‘ 1 ä¸ªè¯´è¯äºº
            "maxSpeakerCount": 6   # ğŸ”¥ æœ€å¤š 6 ä¸ªè¯´è¯äººï¼ˆä¼˜åŒ–å‡†ç¡®ç‡ï¼‰
        }
        print(f"[v112-GOOGLE-DIARIZATION] é…ç½®: minSpeakers=1, maxSpeakers=6ï¼ˆä¼˜åŒ–å‡†ç¡®ç‡ï¼‰")
    
    # æ„å»ºè¯·æ±‚ä½“
    request_body = {
        "config": config,
        "audio": {
            "content": audio_base64
        }
    }
    
    print(f"[v112-GOOGLE] ğŸ“¤ å‘é€è½¬å½•è¯·æ±‚...")
    start_time = time.time()
    
    # å‘é€è¯·æ±‚
    response = requests.post(
        api_url,
        headers={
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        },
        json=request_body,
        timeout=300  # v109: å¢åŠ è¶…æ—¶åˆ° 5 åˆ†é’Ÿ
    )
    
    api_time = time.time() - start_time
    print(f"[v112-GOOGLE] â±ï¸ API å“åº”è€—æ—¶: {api_time:.2f}ç§’")
    
    # æ£€æŸ¥å“åº”
    if response.status_code != 200:
        error_msg = f"Google API é”™è¯¯ [{response.status_code}]: {response.text}"
        raise Exception(error_msg)
    
    # è§£æå“åº”
    result = response.json()
    
    # ğŸŒ æ£€æµ‹å®é™…ä½¿ç”¨çš„è¯­è¨€ï¼ˆå¦‚æœ Google API è¿”å›äº† languageCodeï¼‰
    detected_language = None
    if "results" in result and len(result["results"]) > 0:
        detected_language = result["results"][0].get("languageCode")
        if detected_language:
            print(f"[v112-GOOGLE] ğŸŒ æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_language}")
    
    # ğŸ™ï¸ v110/v112: å¤„ç†å¤šè¯´è¯äººåˆ†ç¦»ç»“æœ
    if enable_diarization and "results" in result:
        print(f"[v112-GOOGLE-DIARIZATION] å¼€å§‹å¤„ç†å¤šè¯´è¯äººè½¬å½•ç»“æœ")
        
        # ğŸ”¥ v112: ä½¿ç”¨æ–°å‚æ•°æ§åˆ¶æ˜¯å¦æ˜¾ç¤ºæ ‡ç­¾
        text = parse_diarization_result(result, remove_speaker_labels=remove_speaker_labels)
        speaker_count = count_unique_speakers(result)
        
        if remove_speaker_labels:
            print(f"[v112-GOOGLE-DIARIZATION] âœ… æ£€æµ‹åˆ° {speaker_count} ä¸ªè¯´è¯äººï¼Œå·²åˆå¹¶å®Œæ•´æ–‡æœ¬ï¼ˆæ— æ ‡ç­¾ï¼‰")
        else:
            print(f"[v112-GOOGLE-DIARIZATION] âœ… æ£€æµ‹åˆ° {speaker_count} ä¸ªè¯´è¯äººï¼ˆå¸¦æ ‡ç­¾ï¼‰")
    else:
        # æ ‡å‡†è½¬å½•ï¼ˆæ— è¯´è¯äººåˆ†ç¦»ï¼‰
        text = ""
        if "results" in result and len(result["results"]) > 0:
            for r in result["results"]:
                if "alternatives" in r and len(r["alternatives"]) > 0:
                    text += r["alternatives"][0].get("transcript", "")
    
    if not text:
        raise Exception("Google API è¿”å›ç©ºæ–‡æœ¬")
    
    print(f"[v112-GOOGLE] âœ… è½¬å½•æˆåŠŸ")
    print(f"[v112-GOOGLE] - æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
    
    metadata = {
        "api": "google",
        "model": "default",
        "status_code": response.status_code,
        "diarization_enabled": enable_diarization,
        "speaker_labels_removed": remove_speaker_labels,  # ğŸ”¥ v112: æ–°å¢æ ‡è¯†
        "detected_language": detected_language,  # ğŸŒ æ·»åŠ æ£€æµ‹åˆ°çš„è¯­è¨€
        "api_response_time": round(api_time, 2)
    }
    
    if enable_diarization:
        metadata["speaker_count"] = count_unique_speakers(result)
    
    return text, metadata


# ================================================================================
# æ ¸å¿ƒ Fallback å‡½æ•°
# ================================================================================

async def transcribe_with_fallback(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, str, Dict[str, Any]]:
    """
    ğŸ¤ v111: éº¦å…‹é£åœºæ™¯æ™ºèƒ½ fallback è½¬å½•
    
    ä¼˜å…ˆçº§ï¼š
    1ï¸âƒ£ AI Builder Space (OpenAI Whisper)
    2ï¸âƒ£ OpenAI Whisper API
    3ï¸âƒ£ Deepgram Nova-2 (å¤‡ç”¨)
    
    Args:
        audio_content: éŸ³é¢‘æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
        filename: æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼Œå¯é€‰ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        Tuple[str, str, dict]: (è½¬å½•æ–‡æœ¬, ä½¿ç”¨çš„API, å…ƒæ•°æ®)
    """
    errors = []
    
    print(f"[v111-DEBUG] ========== å¼€å§‹éº¦å…‹é£åœºæ™¯ Fallback ==========")
    print(f"[v111-DEBUG] éŸ³é¢‘å¤§å°: {len(audio_content) if audio_content else 'None'} bytes")
    print(f"[v111-DEBUG] æ–‡ä»¶å: {filename}")
    print(f"[v111-DEBUG] è¯­è¨€: {language}")
    print(f"[v111-DEBUG] æ—¶é•¿: {duration}")
    
    # ============================================================================
    # 1ï¸âƒ£ å°è¯• AI Builder Space
    # ============================================================================
    print(f"[v111-DEBUG] æ£€æŸ¥ AI Builder æ˜¯å¦å¯ç”¨...")
    ai_builder_should_retry = should_retry_api("ai_builder")
    print(f"[v111-DEBUG] should_retry_api('ai_builder') = {ai_builder_should_retry}")
    
    if ai_builder_should_retry:
        print(f"[v111-DEBUG] âœ… å¼€å§‹å°è¯• AI Builder API...")
        try:
            text, metadata = await _transcribe_ai_builder(
                audio_content, filename, language, duration, logger
            )
            
            print(f"[v111-FALLBACK] âœ… AI Builder Space è½¬å½•æˆåŠŸ")
            print(f"[v111-DEBUG] è¿”å›æ–‡æœ¬é•¿åº¦: {len(text)}")
            return text, "ai_builder", metadata
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"AI Builder: {error_msg}")
            print(f"[v111-FALLBACK] âŒ AI Builder å¤±è´¥: {error_msg}")
            print(f"[v111-DEBUG] AI Builder å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {e}")
            import traceback
            print(f"[v111-DEBUG] AI Builder å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if is_quota_exceeded(None, error_msg):
                API_FALLBACK_STATUS["ai_builder_quota_exceeded"] = True
                API_FALLBACK_STATUS["ai_builder_last_check"] = time.time()
                print(f"[v111-FALLBACK] ğŸš¨ AI Builder é…é¢è€—å°½ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª API")
    else:
        print(f"[v111-FALLBACK] â­ï¸ è·³è¿‡ AI Builderï¼ˆé…é¢å·²è€—å°½ï¼‰")
        print(f"[v111-DEBUG] AI Builder quota_exceeded: {API_FALLBACK_STATUS['ai_builder_quota_exceeded']}")
        errors.append("AI Builder: é…é¢å·²è€—å°½ï¼Œè·³è¿‡")
    
    # ============================================================================
    # 2ï¸âƒ£ å°è¯• OpenAI Whisper API
    # ============================================================================
    print(f"[v111-DEBUG] æ£€æŸ¥ OpenAI æ˜¯å¦å¯ç”¨...")
    openai_should_retry = should_retry_api("openai")
    print(f"[v111-DEBUG] should_retry_api('openai') = {openai_should_retry}")
    
    if openai_should_retry:
        print(f"[v111-DEBUG] âœ… å¼€å§‹å°è¯• OpenAI Whisper API...")
        try:
            text, metadata = await _transcribe_openai(
                audio_content, filename, language, duration, logger
            )
            
            print(f"[v111-FALLBACK] âœ… OpenAI Whisper è½¬å½•æˆåŠŸ (Fallback #2)")
            print(f"[v111-DEBUG] è¿”å›æ–‡æœ¬é•¿åº¦: {len(text)}")
            return text, "openai_whisper", metadata
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"OpenAI: {error_msg}")
            print(f"[v111-FALLBACK] âŒ OpenAI Whisper å¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if is_quota_exceeded(None, error_msg):
                API_FALLBACK_STATUS["openai_quota_exceeded"] = True
                API_FALLBACK_STATUS["openai_last_check"] = time.time()
    else:
        print(f"[v111-FALLBACK] â­ï¸ è·³è¿‡ OpenAIï¼ˆé…é¢å·²è€—å°½ï¼‰")
        errors.append("OpenAI: é…é¢å·²è€—å°½ï¼Œè·³è¿‡")
    
    # ============================================================================
    # 3ï¸âƒ£ å°è¯• Deepgram Nova-2ï¼ˆå¤‡ç”¨ï¼‰
    # ============================================================================
    print(f"[v111-DEBUG] æ£€æŸ¥ Deepgram æ˜¯å¦å¯ç”¨...")
    deepgram_should_retry = should_retry_api("deepgram")
    print(f"[v111-DEBUG] should_retry_api('deepgram') = {deepgram_should_retry}")
    
    if deepgram_should_retry:
        print(f"[v111-DEBUG] âœ… å¼€å§‹å°è¯• Deepgram API (Fallback #3 - å¤‡ç”¨)...")
        try:
            text, metadata = await _transcribe_deepgram(
                audio_content, filename, language, duration, 
                enable_diarization=False,  # éº¦å…‹é£åœºæ™¯ä¸éœ€è¦å¤šè¯´è¯äººè¯†åˆ«
                logger=logger
            )
            
            print(f"[v111-FALLBACK] âœ… Deepgram Nova-2 è½¬å½•æˆåŠŸ (Fallback #3 - å¤‡ç”¨)")
            print(f"[v111-DEBUG] è¿”å›æ–‡æœ¬é•¿åº¦: {len(text)}")
            return text, "deepgram_nova2_chinese", metadata
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"Deepgram: {error_msg}")
            print(f"[v111-FALLBACK] âŒ Deepgram å¤±è´¥: {error_msg}")
            print(f"[v111-DEBUG] Deepgram å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {e}")
            import traceback
            print(f"[v111-DEBUG] Deepgram å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"OpenAI: {error_msg}")
            print(f"[v111-FALLBACK] âŒ OpenAI Whisper å¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if is_quota_exceeded(None, error_msg):
                API_FALLBACK_STATUS["openai_quota_exceeded"] = True
                API_FALLBACK_STATUS["openai_last_check"] = time.time()
    else:
        print(f"[v111-FALLBACK] â­ï¸ è·³è¿‡ OpenAIï¼ˆé…é¢å·²è€—å°½ï¼‰")
        errors.append("OpenAI: é…é¢å·²è€—å°½ï¼Œè·³è¿‡")
    
    # ============================================================================
    # âŒ æ‰€æœ‰ API éƒ½å¤±è´¥
    # ============================================================================
    error_summary = " | ".join(errors)
    print(f"[v111-FALLBACK] ğŸ’¥ æ‰€æœ‰ API éƒ½å¤±è´¥äº†")
    print(f"[v111-FALLBACK] é”™è¯¯æ±‡æ€»: {error_summary}")
    
    raise Exception(f"æ‰€æœ‰è½¬å½• API éƒ½å¤±è´¥äº†: {error_summary}")


# ================================================================================
# ğŸ†• v111: ç³»ç»Ÿ/æ··åˆéŸ³é¢‘ä¸“ç”¨å‡½æ•°ï¼ˆDeepgram + Google åŒä¿é™©ï¼‰
# ================================================================================

async def transcribe_system_audio(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, str, Dict[str, Any]]:
    """
    ğŸ”Š v112: ç³»ç»Ÿ/æ··åˆéŸ³é¢‘è½¬å½•ï¼ˆæ”¯æŒå¤šè¯´è¯äººè¯†åˆ«ï¼Œä¸æ˜¾ç¤ºæ ‡ç­¾ï¼‰
    
    ä¼˜å…ˆçº§ï¼š
    1ï¸âƒ£ OpenAI gpt-4o-transcribe-diarize (å¤šè¯´è¯äººï¼Œæ— æ ‡ç­¾)
    2ï¸âƒ£ Google Cloud Speech-to-Text + Diarization (å¤šè¯´è¯äººï¼Œæ— æ ‡ç­¾)
    3ï¸âƒ£ Deepgram Nova-2 (å¤‡ç”¨)
    
    âœ… ç‰¹æ€§ï¼šè½¬å½•æ‰€æœ‰è¯´è¯äººçš„è¯ï¼Œä½†ä¸æ˜¾ç¤º"Speaker A:", "Speaker B:"ç­‰æ ‡ç­¾
    
    Args:
        audio_content: éŸ³é¢‘æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
        filename: æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼Œå¯é€‰ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        Tuple[str, str, dict]: (è½¬å½•æ–‡æœ¬, ä½¿ç”¨çš„API, å…ƒæ•°æ®)
    """
    print(f"[v112-SYSTEM] ğŸ”Š ç³»ç»Ÿ/æ··åˆéŸ³é¢‘åœºæ™¯ â†’ å¯ç”¨å¤šè¯´è¯äººè¯†åˆ«ï¼ˆæ— æ ‡ç­¾æ¨¡å¼ï¼‰")
    errors = []
    
    # ============================================================================
    # 1ï¸âƒ£ å°è¯• OpenAI gpt-4o-transcribe-diarizeï¼ˆä¸»åŠ›ï¼‰
    # ============================================================================
    try:
        text, metadata = await _transcribe_openai_diarize(
            audio_content=audio_content,
            filename=filename,
            language=language,
            duration=duration,
            logger=logger
        )
        
        # æˆåŠŸï¼æ›´æ–°çŠ¶æ€
        API_FALLBACK_STATUS["last_successful_api"] = "openai_diarize"
        API_FALLBACK_STATUS["api_usage_count"]["openai_diarize"] += 1
        
        print(f"[v112-SYSTEM] âœ… OpenAI Diarize è½¬å½•æˆåŠŸï¼ˆå¤šè¯´è¯äººï¼Œæ— æ ‡ç­¾ï¼‰")
        
        return text, "openai_diarize", metadata
        
    except Exception as e:
        error_msg = str(e)
        errors.append(f"OpenAI Diarize: {error_msg}")
        print(f"[v112-SYSTEM] âŒ OpenAI Diarize å¤±è´¥: {error_msg}")
    
    # ============================================================================
    # 2ï¸âƒ£ å°è¯• Google Cloud Speech-to-Text + Diarizationï¼ˆæ— æ ‡ç­¾ï¼‰
    # ============================================================================
    try:
        text, metadata = await _transcribe_google(
            audio_content=audio_content,
            filename=filename,
            language=language,
            logger=logger,
            enable_diarization=True,  # ğŸ¤ å¯ç”¨å¤šè¯´è¯äººè¯†åˆ«
            remove_speaker_labels=True  # ğŸ”¥ v112: ä¸æ˜¾ç¤ºè¯´è¯äººæ ‡ç­¾
        )
        
        # æˆåŠŸï¼æ›´æ–°çŠ¶æ€
        API_FALLBACK_STATUS["last_successful_api"] = "google"
        API_FALLBACK_STATUS["api_usage_count"]["google"] += 1
        
        print(f"[v112-SYSTEM] âœ… Google API è½¬å½•æˆåŠŸï¼ˆå¤šè¯´è¯äººï¼Œæ— æ ‡ç­¾ï¼‰(Fallback #2)")
        
        return text, "google", metadata
        
    except Exception as e:
        error_msg = str(e)
        errors.append(f"Google: {error_msg}")
        print(f"[v112-SYSTEM] âŒ Google API å¤±è´¥: {error_msg}")
    
    # ============================================================================
    # 3ï¸âƒ£ å°è¯• Deepgram Nova-2 + Diarizationï¼ˆå¤‡ç”¨ï¼‰
    # ============================================================================
    if should_retry_api("deepgram"):
        try:
            text, metadata = await _transcribe_deepgram(
                audio_content=audio_content,
                filename=filename,
                language=language,
                duration=duration,
                enable_diarization=True,  # ğŸ¤ å¯ç”¨å¤šè¯´è¯äººè¯†åˆ«
                logger=logger
            )
            
            # æˆåŠŸï¼æ›´æ–°çŠ¶æ€
            API_FALLBACK_STATUS["last_successful_api"] = "deepgram"
            API_FALLBACK_STATUS["api_usage_count"]["deepgram"] += 1
            
            print(f"[v112-SYSTEM] âœ… Deepgram Nova-2 è½¬å½•æˆåŠŸï¼ˆå¤šè¯´è¯äººï¼‰(Fallback #3 - å¤‡ç”¨)")
            
            return text, "deepgram_nova2_chinese", metadata
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"Deepgram: {error_msg}")
            print(f"[v112-SYSTEM] âŒ Deepgram å¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if is_quota_exceeded(None, error_msg):
                API_FALLBACK_STATUS["deepgram_quota_exceeded"] = True
                API_FALLBACK_STATUS["deepgram_last_check"] = time.time()
                print(f"[v112-SYSTEM] ğŸš¨ Deepgram é…é¢è€—å°½")
    else:
        print(f"[v112-SYSTEM] â­ï¸ è·³è¿‡ Deepgramï¼ˆé…é¢å·²è€—å°½ï¼‰")
        errors.append("Deepgram: é…é¢å·²è€—å°½ï¼Œè·³è¿‡")
    
    # ============================================================================
    # âŒ æ‰€æœ‰ API éƒ½å¤±è´¥
    # ============================================================================
    error_summary = " | ".join(errors)
    print(f"[v112-SYSTEM] ğŸ’¥ æ‰€æœ‰ç³»ç»ŸéŸ³é¢‘ API éƒ½å¤±è´¥äº†")
    print(f"[v112-SYSTEM] é”™è¯¯æ±‡æ€»: {error_summary}")
    
    raise Exception(f"ç³»ç»ŸéŸ³é¢‘è½¬å½•å¤±è´¥ï¼ˆæ‰€æœ‰ APIï¼‰: {error_summary}")


# ================================================================================
# çŠ¶æ€æŸ¥è¯¢å‡½æ•°
# ================================================================================

def get_api_status() -> Dict[str, Any]:
    """
    è·å–å½“å‰ API fallback çŠ¶æ€
    
    Returns:
        dict: API çŠ¶æ€ä¿¡æ¯
    """
    return {
        "deepgram": {  # ğŸ†• v111
            "available": not API_FALLBACK_STATUS["deepgram_quota_exceeded"],
            "quota_exceeded": API_FALLBACK_STATUS["deepgram_quota_exceeded"],
            "last_check": API_FALLBACK_STATUS["deepgram_last_check"],
            "usage_count": API_FALLBACK_STATUS["api_usage_count"]["deepgram"]
        },
        "ai_builder": {
            "available": not API_FALLBACK_STATUS["ai_builder_quota_exceeded"],
            "quota_exceeded": API_FALLBACK_STATUS["ai_builder_quota_exceeded"],
            "last_check": API_FALLBACK_STATUS["ai_builder_last_check"],
            "usage_count": API_FALLBACK_STATUS["api_usage_count"]["ai_builder"]
        },
        "openai": {
            "available": not API_FALLBACK_STATUS["openai_quota_exceeded"],
            "quota_exceeded": API_FALLBACK_STATUS["openai_quota_exceeded"],
            "last_check": API_FALLBACK_STATUS["openai_last_check"],
            "usage_count": API_FALLBACK_STATUS["api_usage_count"]["openai"]
        },
        "google": {
            "available": True,
            "usage_count": API_FALLBACK_STATUS["api_usage_count"]["google"]
        },
        "last_successful_api": API_FALLBACK_STATUS["last_successful_api"]
    }
