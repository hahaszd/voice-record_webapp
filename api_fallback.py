"""
API Fallback Module for Speech-to-Text
ğŸ”¥ v111: å¼•å…¥ Deepgram Nova-3 Multilingual ä½œä¸ºä¸»åŠ› API

ä¼˜å…ˆçº§ç­–ç•¥ï¼š
éº¦å…‹é£åœºæ™¯ï¼š
1. Deepgram Nova-3 Multilingual - $0.0077/min
2. AI Builder Space (OpenAI Whisper) - å…è´¹ $100
3. OpenAI Whisper API - $0.006/min

ç³»ç»Ÿ/æ··åˆåœºæ™¯ï¼š
1. Deepgram Nova-3 Multilingual - $0.0077/min + Diarization
2. Google Cloud Speech-to-Text - $0.016/min + Diarization
"""

import os
import time
import json
import base64
import requests
from typing import Tuple, Dict, Any, Optional
from logging_helper import TranscriptionLogger

# ================================================================================
# å…¨å±€çŠ¶æ€ç®¡ç†ï¼ˆæœåŠ¡å™¨é‡å¯åé‡ç½®ï¼‰
# ================================================================================

API_FALLBACK_STATUS = {
    "ai_builder_quota_exceeded": False,
    "ai_builder_last_check": None,
    "openai_quota_exceeded": False,
    "openai_last_check": None,
    "deepgram_quota_exceeded": False,  # ğŸ†• v111: Deepgram
    "deepgram_last_check": None,
    "last_successful_api": "deepgram",  # ğŸ†• v111: Deepgram ä¸ºä¸»åŠ›
    "api_usage_count": {
        "deepgram": 0,  # ğŸ†• v111: Deepgram
        "ai_builder": 0,
        "openai": 0,
        "google": 0
    }
}

# æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡ä¸» API æ˜¯å¦æ¢å¤ï¼ˆç§’ï¼‰
QUOTA_RECHECK_INTERVAL = 3600  # 1 å°æ—¶


# ================================================================================
# é”™è¯¯æ£€æµ‹è¾…åŠ©å‡½æ•°
# ================================================================================

def is_quota_exceeded(status_code: Optional[int], error_message: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦æ˜¯ quota è€—å°½é”™è¯¯
    
    Args:
        status_code: HTTP çŠ¶æ€ç 
        error_message: é”™è¯¯ä¿¡æ¯
    
    Returns:
        bool: True è¡¨ç¤º quota è€—å°½
    """
    if not error_message:
        return False
    
    error_lower = str(error_message).lower()
    
    # å¸¸è§çš„ quota è€—å°½æŒ‡ç¤ºç¬¦
    quota_keywords = [
        "quota",
        "exceeded",
        "insufficient",
        "limit reached",
        "out of credits",
        "insufficient_quota",
        "rate_limit_exceeded",
        "billing",
        "payment required"
    ]
    
    # æ£€æŸ¥å…³é”®è¯
    has_quota_keyword = any(keyword in error_lower for keyword in quota_keywords)
    
    # æ£€æŸ¥ HTTP çŠ¶æ€ç 
    is_quota_status = status_code in [402, 429]  # 402: Payment Required, 429: Too Many Requests
    
    return has_quota_keyword or is_quota_status


def is_temporary_error(status_code: Optional[int], error_message: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦æ˜¯ä¸´æ—¶é”™è¯¯ï¼ˆå€¼å¾—é‡è¯•ï¼‰
    
    Args:
        status_code: HTTP çŠ¶æ€ç 
        error_message: é”™è¯¯ä¿¡æ¯
    
    Returns:
        bool: True è¡¨ç¤ºæ˜¯ä¸´æ—¶é”™è¯¯
    """
    if not error_message:
        return False
    
    error_lower = str(error_message).lower()
    
    # ä¸´æ—¶é”™è¯¯å…³é”®è¯
    temp_keywords = [
        "timeout",
        "connection",
        "network",
        "temporary",
        "unavailable",
        "try again"
    ]
    
    # æ£€æŸ¥å…³é”®è¯
    has_temp_keyword = any(keyword in error_lower for keyword in temp_keywords)
    
    # æ£€æŸ¥ HTTP çŠ¶æ€ç 
    is_temp_status = status_code in [500, 502, 503, 504]  # æœåŠ¡å™¨é”™è¯¯
    
    return has_temp_keyword or is_temp_status


def should_retry_api(api_name: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•æŸä¸ª API
    
    Args:
        api_name: API åç§° ("deepgram", "ai_builder", "openai")
    
    Returns:
        bool: True è¡¨ç¤ºåº”è¯¥é‡è¯•
    """
    # ğŸ†• v111: Deepgram
    if api_name == "deepgram":
        if API_FALLBACK_STATUS["deepgram_quota_exceeded"]:
            last_check = API_FALLBACK_STATUS["deepgram_last_check"]
            if last_check and (time.time() - last_check) < QUOTA_RECHECK_INTERVAL:
                return False
            print(f"[v111-FALLBACK] Deepgram quota æ£€æŸ¥é—´éš”å·²è¿‡ï¼Œå°è¯•é‡æ–°æ£€æµ‹")
            return True
        return True
    
    elif api_name == "ai_builder":
        # å¦‚æœæ ‡è®°ä¸º quota è€—å°½
        if API_FALLBACK_STATUS["ai_builder_quota_exceeded"]:
            # æ£€æŸ¥æ˜¯å¦è¿‡äº†é‡æ–°æ£€æŸ¥é—´éš”
            last_check = API_FALLBACK_STATUS["ai_builder_last_check"]
            if last_check and (time.time() - last_check) < QUOTA_RECHECK_INTERVAL:
                return False  # è¿˜æ²¡åˆ°é‡æ–°æ£€æŸ¥çš„æ—¶é—´
            # è¿‡äº†é—´éš”ï¼Œå¯ä»¥é‡è¯•ä¸€æ¬¡
            print(f"[FALLBACK] AI Builder Space quota æ£€æŸ¥é—´éš”å·²è¿‡ï¼Œå°è¯•é‡æ–°æ£€æµ‹")
            return True
        return True
    
    elif api_name == "openai":
        if API_FALLBACK_STATUS["openai_quota_exceeded"]:
            last_check = API_FALLBACK_STATUS["openai_last_check"]
            if last_check and (time.time() - last_check) < QUOTA_RECHECK_INTERVAL:
                return False
            print(f"[FALLBACK] OpenAI quota æ£€æŸ¥é—´éš”å·²è¿‡ï¼Œå°è¯•é‡æ–°æ£€æµ‹")
            return True
        return True
    
    return True


# ================================================================================
# ğŸ†• v111: API è°ƒç”¨å‡½æ•° - Deepgram Nova-3 Multilingual
# ================================================================================

async def _transcribe_deepgram(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    enable_diarization: bool = False,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, Dict[str, Any]]:
    """
    è°ƒç”¨ Deepgram Nova-3 Multilingual API è¿›è¡Œè½¬å½•
    
    ç‰¹ç‚¹ï¼š
    - å¤šè¯­è¨€æ”¯æŒï¼ˆ90+ è¯­è¨€ï¼‰
    - å¯é€‰å¤šè¯´è¯äººè¯†åˆ«ï¼ˆDiarizationï¼‰
    - é«˜å‡†ç¡®ç‡ï¼ˆæœ€æ–° Nova-3 æ¨¡å‹ï¼‰
    - å¿«é€Ÿå“åº”
    
    Args:
        audio_content: éŸ³é¢‘æ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹
        filename: éŸ³é¢‘æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼ŒDeepgram æ”¯æŒè‡ªåŠ¨æ£€æµ‹ï¼‰
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        enable_diarization: æ˜¯å¦å¯ç”¨å¤šè¯´è¯äººè¯†åˆ«
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    from server2 import DEEPGRAM_API_KEY
    
    if not DEEPGRAM_API_KEY:
        raise Exception("DEEPGRAM_API_KEY æœªé…ç½®")
    
    try:
        from deepgram import DeepgramClient, PrerecordedOptions
        
        print(f"[v111-DEEPGRAM] ğŸš€ å¼€å§‹è°ƒç”¨ Deepgram Nova-3 Multilingual API")
        print(f"[v111-DEEPGRAM] - æ–‡ä»¶å: {filename}")
        print(f"[v111-DEEPGRAM] - éŸ³é¢‘å¤§å°: {len(audio_content) / 1024:.2f} KB")
        if duration:
            print(f"[v111-DEEPGRAM] - æ—¶é•¿: {duration}ç§’")
        print(f"[v111-DEEPGRAM] - å¤šè¯´è¯äººè¯†åˆ«: {'âœ… å¯ç”¨' if enable_diarization else 'âŒ ç¦ç”¨'}")
        
        # åˆå§‹åŒ– Deepgram å®¢æˆ·ç«¯
        deepgram = DeepgramClient(DEEPGRAM_API_KEY)
        
        # é…ç½®è½¬å½•é€‰é¡¹
        options = PrerecordedOptions(
            model="nova-3",  # Nova-3 æœ€æ–°æ¨¡å‹
            language="multi",  # Multilingual å¤šè¯­è¨€æ¨¡å¼
            smart_format=True,  # æ™ºèƒ½æ ¼å¼åŒ–ï¼ˆæ ‡ç‚¹ã€å¤§å°å†™ï¼‰
            punctuate=True,  # æ·»åŠ æ ‡ç‚¹
            diarize=enable_diarization,  # å¤šè¯´è¯äººè¯†åˆ«
            paragraphs=True,  # æ®µè½åˆ†å‰²
        )
        
        print(f"[v111-DEEPGRAM] ğŸ“¤ å‘é€è½¬å½•è¯·æ±‚...")
        start_time = time.time()
        
        # è°ƒç”¨ Deepgram API
        response = deepgram.listen.rest.v("1").transcribe_file(
            {"buffer": audio_content},
            options
        )
        
        api_time = time.time() - start_time
        print(f"[v111-DEEPGRAM] â±ï¸ API å“åº”è€—æ—¶: {api_time:.2f}ç§’")
        
        # è§£æå“åº”
        result = response.results.channels[0].alternatives[0]
        transcription_text = result.transcript
        
        if not transcription_text or not transcription_text.strip():
            raise Exception("Deepgram è¿”å›ç©ºè½¬å½•ç»“æœ")
        
        print(f"[v111-DEEPGRAM] âœ… è½¬å½•æˆåŠŸ")
        print(f"[v111-DEEPGRAM] - æ–‡æœ¬é•¿åº¦: {len(transcription_text)} å­—ç¬¦")
        
        # æå–å…ƒæ•°æ®
        metadata = {
            "api": "deepgram_nova3_multilingual",
            "model": "nova-3",
            "language_mode": "multilingual",
            "confidence": result.confidence if hasattr(result, 'confidence') else None,
            "api_response_time": round(api_time, 2),
            "audio_duration": duration,
            "diarization_enabled": enable_diarization,
        }
        
        # å¦‚æœå¯ç”¨äº†å¤šè¯´è¯äººè¯†åˆ«ï¼Œå¤„ç†è¯´è¯äººæ ‡ç­¾
        if enable_diarization and hasattr(result, 'words') and result.words:
            print(f"[v111-DEEPGRAM] ğŸ¤ æ£€æµ‹åˆ°å¤šè¯´è¯äººä¿¡æ¯")
            speakers = set()
            for word in result.words:
                if hasattr(word, 'speaker'):
                    speakers.add(word.speaker)
            
            if len(speakers) > 1:
                print(f"[v111-DEEPGRAM] - æ£€æµ‹åˆ° {len(speakers)} ä¸ªè¯´è¯äºº")
                metadata["num_speakers"] = len(speakers)
                
                # æ ¼å¼åŒ–å¸¦è¯´è¯äººæ ‡ç­¾çš„æ–‡æœ¬
                formatted_text = []
                current_speaker = None
                current_text = []
                
                for word in result.words:
                    if hasattr(word, 'speaker'):
                        if current_speaker is None:
                            current_speaker = word.speaker
                        elif word.speaker != current_speaker:
                            # åˆ‡æ¢è¯´è¯äºº
                            if current_text:
                                formatted_text.append(f"Speaker {current_speaker}: {' '.join(current_text)}")
                            current_speaker = word.speaker
                            current_text = []
                    
                    if hasattr(word, 'punctuated_word'):
                        current_text.append(word.punctuated_word)
                
                # æ·»åŠ æœ€åä¸€ä¸ªè¯´è¯äººçš„æ–‡æœ¬
                if current_text:
                    formatted_text.append(f"Speaker {current_speaker}: {' '.join(current_text)}")
                
                if formatted_text:
                    transcription_text = "\n".join(formatted_text)
                    print(f"[v111-DEEPGRAM] âœ… å·²æ ¼å¼åŒ–å¤šè¯´è¯äººæ–‡æœ¬")
        
        # è®°å½•æ—¥å¿—
        if logger:
            logger.log_api_call(
                api_name="deepgram_nova3_multilingual",
                status="success",
                response_time=api_time,
                audio_duration=duration,
                text_length=len(transcription_text),
                metadata=metadata
            )
        
        # æ›´æ–°å…¨å±€çŠ¶æ€
        API_FALLBACK_STATUS["api_usage_count"]["deepgram"] += 1
        API_FALLBACK_STATUS["last_successful_api"] = "deepgram"
        
        return transcription_text, metadata
        
    except Exception as e:
        error_msg = str(e)
        print(f"[v111-DEEPGRAM] âŒ Deepgram API è°ƒç”¨å¤±è´¥: {error_msg}")
        
        # è®°å½•å¤±è´¥æ—¥å¿—
        if logger:
            logger.log_api_call(
                api_name="deepgram_nova3_multilingual",
                status="error",
                error_message=error_msg,
                audio_duration=duration
            )
        
        raise Exception(f"Deepgram API è½¬å½•å¤±è´¥: {error_msg}")


# ================================================================================
# API è°ƒç”¨å‡½æ•° - AI Builder Space
# ================================================================================

async def _transcribe_ai_builder(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, Dict[str, Any]]:
    """
    è°ƒç”¨ AI Builder Space API è¿›è¡Œè½¬å½•
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    from server2 import AI_BUILDER_TOKEN, AI_BUILDER_API_BASE
    
    if not AI_BUILDER_TOKEN:
        raise Exception("AI_BUILDER_TOKEN æœªé…ç½®")
    
    print(f"[FALLBACK] å°è¯•ä½¿ç”¨ AI Builder Space API")
    print(f"[v109-FIX] ğŸ”§ æ·»åŠ  Prompt å‚æ•°ï¼Œå°è¯•è§£å†³å†…å®¹æˆªæ–­é—®é¢˜")
    print(f"[v109-FIX] ğŸ”§ è¶…æ—¶å¢åŠ åˆ° 300 ç§’ï¼Œresponse_format æ”¹ä¸º verbose_json")
    
    # å‡†å¤‡è¯·æ±‚
    api_url = f"{AI_BUILDER_API_BASE}/audio/transcriptions"
    
    # ğŸ”¥ AI Builder Space ä½¿ç”¨ 'audio_file' ä½œä¸ºå­—æ®µåï¼ˆä¸æ˜¯ 'file'ï¼‰
    files = {
        'audio_file': (filename, audio_content, 'audio/wav')
    }
    
    # ğŸ”§ v109: æ·»åŠ  prompt å‚æ•°ï¼Œè§£å†³å†…å®¹æˆªæ–­é—®é¢˜
    # ğŸŒ v110: æ¢å¤è‡ªåŠ¨è¯­è¨€è¯†åˆ«ï¼ˆç§»é™¤ v108-TEST å¼ºåˆ¶è‹±æ–‡ï¼‰
    form_data = {
        'model': 'whisper-1',
        'response_format': 'verbose_json',  # v109: æ”¹ä¸º verbose è·å–æ›´å¤šä¿¡æ¯
        'prompt': 'This is a continuous recording containing both human speech and video/audio playback (such as YouTube). Please transcribe all audio content completely and accurately, including all speech, video audio, and background sounds throughout the entire recording.'  # v109: å¼•å¯¼å®Œæ•´è½¬å½•
    }
    
    # ğŸŒ v110: å¦‚æœæŒ‡å®šäº†è¯­è¨€ï¼Œåˆ™ä½¿ç”¨æŒ‡å®šè¯­è¨€ï¼›å¦åˆ™è‡ªåŠ¨æ£€æµ‹
    if language:
        form_data['language'] = language
        print(f"[v110-WHISPER] æŒ‡å®šè¯­è¨€: {language}")
    else:
        print(f"[v110-WHISPER] ğŸŒ ä½¿ç”¨è‡ªåŠ¨è¯­è¨€è¯†åˆ«")
    
    # å‘é€è¯·æ±‚
    response = requests.post(
        api_url,
        headers={
            "Authorization": f"Bearer {AI_BUILDER_TOKEN}",
            "Accept": "application/json"
        },
        files=files,
        data=form_data,
        timeout=300  # v109: å¢åŠ è¶…æ—¶åˆ° 5 åˆ†é’Ÿï¼Œé¿å…é•¿éŸ³é¢‘è¢«æˆªæ–­
    )
    
    # æ£€æŸ¥å“åº”
    if response.status_code != 200:
        error_msg = f"AI Builder Space API é”™è¯¯ [{response.status_code}]: {response.text}"
        raise Exception(error_msg)
    
    # è§£æå“åº”
    result = response.json()
    
    # v109: æ”¯æŒ verbose_json æ ¼å¼
    if isinstance(result, dict) and 'text' in result:
        text = result.get('text', '')
    else:
        text = result if isinstance(result, str) else str(result)
    
    if not text:
        raise Exception("AI Builder Space API è¿”å›ç©ºæ–‡æœ¬")
    
    # v109: è®°å½• verbose ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'segments' in result:
        segments_count = len(result['segments'])
        print(f"[v109-DEBUG] è½¬å½•åŒ…å« {segments_count} ä¸ªéŸ³é¢‘æ®µè½")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ®µè½è¢«æ ‡è®°ä¸º"éè¯­éŸ³"
        for i, seg in enumerate(result['segments']):
            no_speech_prob = seg.get('no_speech_prob', 0)
            if no_speech_prob > 0.5:
                print(f"[v109-WARNING] æ®µè½ {i} è¢«åˆ¤æ–­ä¸ºéè¯­éŸ³ (æ¦‚ç‡: {no_speech_prob:.2f})")
    
    metadata = {
        "api": "ai_builder",
        "model": "whisper-1",
        "status_code": response.status_code
    }
    
    return text, metadata


# ================================================================================
# API è°ƒç”¨å‡½æ•° - OpenAI Whisper
# ================================================================================

async def _transcribe_openai(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, Dict[str, Any]]:
    """
    ç›´æ¥è°ƒç”¨ OpenAI Whisper API è¿›è¡Œè½¬å½•
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    
    if not openai_api_key:
        raise Exception("OPENAI_API_KEY æœªé…ç½®")
    
    print(f"[FALLBACK] å°è¯•ä½¿ç”¨ OpenAI Whisper API")
    print(f"[v109-FIX] ğŸ”§ æ·»åŠ  Prompt å‚æ•°ï¼Œå°è¯•è§£å†³å†…å®¹æˆªæ–­é—®é¢˜")
    
    # OpenAI API endpoint
    api_url = "https://api.openai.com/v1/audio/transcriptions"
    
    # å‡†å¤‡è¯·æ±‚
    files = {
        'file': (filename, audio_content, 'audio/wav')
    }
    
    # ğŸ”§ v109: æ·»åŠ  prompt å‚æ•°
    # ğŸŒ v110: æ¢å¤è‡ªåŠ¨è¯­è¨€è¯†åˆ«ï¼ˆç§»é™¤ v108-TEST å¼ºåˆ¶è‹±æ–‡ï¼‰
    data = {
        'model': 'whisper-1',
        'response_format': 'verbose_json',  # v109: æ”¹ä¸º verbose
        'prompt': 'This is a continuous recording containing both human speech and video/audio playback (such as YouTube). Please transcribe all audio content completely and accurately, including all speech, video audio, and background sounds throughout the entire recording.'  # v109: å¼•å¯¼å®Œæ•´è½¬å½•
    }
    
    # ğŸŒ v110: å¦‚æœæŒ‡å®šäº†è¯­è¨€ï¼Œåˆ™ä½¿ç”¨æŒ‡å®šè¯­è¨€ï¼›å¦åˆ™è‡ªåŠ¨æ£€æµ‹
    if language:
        data['language'] = language
        print(f"[v110-WHISPER] æŒ‡å®šè¯­è¨€: {language}")
    else:
        print(f"[v110-WHISPER] ğŸŒ ä½¿ç”¨è‡ªåŠ¨è¯­è¨€è¯†åˆ«")
    
    # å‘é€è¯·æ±‚
    response = requests.post(
        api_url,
        headers={
            "Authorization": f"Bearer {openai_api_key}"
        },
        files=files,
        data=data,
        timeout=300  # v109: å¢åŠ è¶…æ—¶åˆ° 5 åˆ†é’Ÿ
    )
    
    # æ£€æŸ¥å“åº”
    if response.status_code != 200:
        error_msg = f"OpenAI API é”™è¯¯ [{response.status_code}]: {response.text}"
        raise Exception(error_msg)
    
    # è§£æå“åº”
    result = response.json()
    
    # v109: æ”¯æŒ verbose_json æ ¼å¼
    if isinstance(result, dict) and 'text' in result:
        text = result.get('text', '')
    else:
        text = result if isinstance(result, str) else str(result)
    
    if not text:
        raise Exception("OpenAI API è¿”å›ç©ºæ–‡æœ¬")
    
    # v109: è®°å½• verbose ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'segments' in result:
        segments_count = len(result['segments'])
        print(f"[v109-DEBUG] OpenAI è½¬å½•åŒ…å« {segments_count} ä¸ªéŸ³é¢‘æ®µè½")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ®µè½è¢«æ ‡è®°ä¸º"éè¯­éŸ³"
        for i, seg in enumerate(result['segments']):
            no_speech_prob = seg.get('no_speech_prob', 0)
            if no_speech_prob > 0.5:
                start = seg.get('start', 0)
                end = seg.get('end', 0)
                print(f"[v109-WARNING] æ®µè½ {i} ({start:.1f}s-{end:.1f}s) è¢«åˆ¤æ–­ä¸ºéè¯­éŸ³ (æ¦‚ç‡: {no_speech_prob:.2f})")
    
    metadata = {
        "api": "openai",
        "model": "whisper-1",
        "status_code": response.status_code
    }
    
    return text, metadata


# ================================================================================
# API è°ƒç”¨å‡½æ•° - Google Cloud Speech-to-Text
# ================================================================================

def convert_language_code_for_google(lang_code: str) -> str:
    """
    å°†æ ‡å‡†è¯­è¨€ä»£ç è½¬æ¢ä¸º Google Cloud Speech-to-Text æ ¼å¼
    
    Args:
        lang_code: æ ‡å‡†è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en', 'zh'ï¼‰
    
    Returns:
        str: Google æ ¼å¼çš„è¯­è¨€ä»£ç ï¼ˆå¦‚ 'en-US', 'zh-CN'ï¼‰
    """
    # å¸¸è§è¯­è¨€æ˜ å°„
    google_lang_map = {
        'en': 'en-US',
        'zh': 'zh-CN',
        'es': 'es-ES',
        'fr': 'fr-FR',
        'de': 'de-DE',
        'ja': 'ja-JP',
        'ko': 'ko-KR',
        'pt': 'pt-BR',
        'ru': 'ru-RU',
        'ar': 'ar-SA',
        'it': 'it-IT',
        'nl': 'nl-NL',
        'tr': 'tr-TR',
        'pl': 'pl-PL',
        'sv': 'sv-SE',
        'da': 'da-DK',
        'fi': 'fi-FI',
        'no': 'no-NO',
        'cs': 'cs-CZ',
        'el': 'el-GR',
        'he': 'he-IL',
        'hi': 'hi-IN',
        'id': 'id-ID',
        'ms': 'ms-MY',
        'th': 'th-TH',
        'vi': 'vi-VN',
        'uk': 'uk-UA',
        'ro': 'ro-RO',
        'sk': 'sk-SK',
        'bg': 'bg-BG',
        'hr': 'hr-HR',
        'sr': 'sr-RS',
        'ca': 'ca-ES',
        'hu': 'hu-HU',
        'lt': 'lt-LT',
        'lv': 'lv-LV',
        'et': 'et-EE',
        'sl': 'sl-SI',
    }
    
    # å¦‚æœå·²ç»æ˜¯æ­£ç¡®æ ¼å¼ï¼ˆå¦‚ 'en-US'ï¼‰ï¼Œç›´æ¥è¿”å›
    if '-' in lang_code:
        return lang_code
    
    # æŸ¥æ‰¾æ˜ å°„
    return google_lang_map.get(lang_code, f'{lang_code}-{lang_code.upper()}')


# ================================================================================
# ğŸ™ï¸ v110: å¤šè¯´è¯äººåˆ†ç¦»è¾…åŠ©å‡½æ•°
# ================================================================================

def count_unique_speakers(result: Dict[str, Any]) -> int:
    """
    ç»Ÿè®¡æ£€æµ‹åˆ°çš„è¯´è¯äººæ•°é‡
    
    Args:
        result: Google API è¿”å›çš„ç»“æœ
    
    Returns:
        int: è¯´è¯äººæ•°é‡
    """
    speakers = set()
    
    if "results" in result:
        for r in result["results"]:
            if "alternatives" in r and len(r["alternatives"]) > 0:
                words = r["alternatives"][0].get("words", [])
                for word in words:
                    speaker_tag = word.get("speakerTag")
                    if speaker_tag:
                        speakers.add(speaker_tag)
    
    return len(speakers)


def parse_diarization_result(result: Dict[str, Any]) -> str:
    """
    è§£æå¤šè¯´è¯äººåˆ†ç¦»ç»“æœï¼Œæ ¼å¼åŒ–è¾“å‡º
    
    Args:
        result: Google API è¿”å›çš„ç»“æœ
    
    Returns:
        str: æ ¼å¼åŒ–çš„è½¬å½•æ–‡æœ¬ï¼ˆåŒ…å«è¯´è¯äººæ ‡ç­¾ï¼‰
    """
    # æ”¶é›†æ‰€æœ‰ words åŠå…¶ speaker tag
    all_words = []
    
    if "results" in result:
        for r in result["results"]:
            if "alternatives" in r and len(r["alternatives"]) > 0:
                words = r["alternatives"][0].get("words", [])
                for word in words:
                    all_words.append({
                        "word": word.get("word", ""),
                        "speaker": word.get("speakerTag", 0),
                        "startTime": word.get("startTime", "0s"),
                        "endTime": word.get("endTime", "0s")
                    })
    
    if not all_words:
        # å¦‚æœæ²¡æœ‰ word-level æ•°æ®ï¼Œé€€å›åˆ°æ ‡å‡†æ ¼å¼
        text = ""
        if "results" in result:
            for r in result["results"]:
                if "alternatives" in r and len(r["alternatives"]) > 0:
                    text += r["alternatives"][0].get("transcript", "")
        return text
    
    # æŒ‰è¯´è¯äººåˆ†ç»„
    current_speaker = None
    segments = []
    current_segment = []
    
    for word_info in all_words:
        speaker = word_info["speaker"]
        word = word_info["word"]
        
        if speaker != current_speaker:
            # è¯´è¯äººåˆ‡æ¢
            if current_segment:
                segments.append({
                    "speaker": current_speaker,
                    "text": " ".join(current_segment)
                })
            current_speaker = speaker
            current_segment = [word]
        else:
            current_segment.append(word)
    
    # æ·»åŠ æœ€åä¸€ä¸ª segment
    if current_segment:
        segments.append({
            "speaker": current_speaker,
            "text": " ".join(current_segment)
        })
    
    # æ ¼å¼åŒ–è¾“å‡º
    if len(segments) == 1:
        # åªæœ‰ä¸€ä¸ªè¯´è¯äººï¼Œç›´æ¥è¿”å›æ–‡æœ¬ï¼ˆä¸æ·»åŠ æ ‡ç­¾ï¼‰
        return segments[0]["text"]
    else:
        # å¤šä¸ªè¯´è¯äººï¼Œæ·»åŠ æ ‡ç­¾
        formatted_lines = []
        for seg in segments:
            formatted_lines.append(f"Speaker {seg['speaker']}: {seg['text']}")
        return "\n".join(formatted_lines)


async def _transcribe_google(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    logger: Optional[TranscriptionLogger] = None,
    enable_diarization: bool = False  # ğŸ™ï¸ v110: æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»
) -> Tuple[str, Dict[str, Any]]:
    """
    è°ƒç”¨ Google Cloud Speech-to-Text API è¿›è¡Œè½¬å½•
    ğŸ™ï¸ v110: æ”¯æŒå¤šè¯´è¯äººåˆ†ç¦»ï¼ˆSpeaker Diarizationï¼‰
    
    Args:
        audio_content: éŸ³é¢‘å†…å®¹
        filename: æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨è¯†åˆ«ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨
        enable_diarization: æ˜¯å¦å¯ç”¨å¤šè¯´è¯äººåˆ†ç¦»
    
    Returns:
        Tuple[str, dict]: (è½¬å½•æ–‡æœ¬, å…ƒæ•°æ®)
    """
    from server2 import get_access_token, get_project_id
    
    print(f"[FALLBACK] å°è¯•ä½¿ç”¨ Google Cloud Speech-to-Text API")
    if enable_diarization:
        print(f"[v110-DIARIZATION] ğŸ™ï¸ å¯ç”¨å¤šè¯´è¯äººåˆ†ç¦»ï¼ˆSpeaker Diarizationï¼‰")
    
    # è·å–è®¿é—®ä»¤ç‰Œå’Œé¡¹ç›® ID
    access_token = get_access_token()
    project_id = get_project_id()
    
    # Google API endpoint
    api_url = f"https://speech.googleapis.com/v1/speech:recognize"
    
    # ç¼–ç éŸ³é¢‘
    audio_base64 = base64.b64encode(audio_content).decode('utf-8')
    
    # æ„å»ºåŸºç¡€é…ç½®
    config = {
        "encoding": "LINEAR16",
        "sampleRateHertz": 48000,
        "enableAutomaticPunctuation": True,
        "model": "default"
    }
    
    # ğŸŒ è¯­è¨€è®¾ç½®ï¼ˆæ”¯æŒè‹±æ–‡+ä¸­æ–‡åŒè¯­è‡ªåŠ¨æ£€æµ‹ï¼‰
    if language:
        # ç”¨æˆ·æŒ‡å®šäº†è¯­è¨€
        config["languageCode"] = convert_language_code_for_google(language)
        print(f"[v110-GOOGLE] æŒ‡å®šè¯­è¨€: {config['languageCode']}")
    else:
        # é»˜è®¤ä½¿ç”¨è‹±æ–‡+ä¸­æ–‡åŒè¯­æ”¯æŒï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
        config["languageCode"] = "en-US"  # ä¸»è¦è¯­è¨€
        config["alternativeLanguageCodes"] = ["zh-CN"]  # å¤‡é€‰ä¸­æ–‡
        print(f"[v110-GOOGLE] ğŸŒ åŒè¯­æ¨¡å¼: ä¸»è¯­è¨€ en-US, å¤‡é€‰ zh-CNï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰")
    
    # ğŸ™ï¸ v110: æ·»åŠ å¤šè¯´è¯äººåˆ†ç¦»é…ç½®
    if enable_diarization:
        config["diarizationConfig"] = {
            "enableSpeakerDiarization": True,
            "minSpeakerCount": 1,
            "maxSpeakerCount": 10  # æ”¯æŒæœ€å¤š 10 ä¸ªè¯´è¯äºº
        }
        print(f"[v110-DIARIZATION] é…ç½®: minSpeakers=1, maxSpeakers=10")
    
    # æ„å»ºè¯·æ±‚ä½“
    request_body = {
        "config": config,
        "audio": {
            "content": audio_base64
        }
    }
    
    # å‘é€è¯·æ±‚
    response = requests.post(
        api_url,
        headers={
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        },
        json=request_body,
        timeout=300  # v109: å¢åŠ è¶…æ—¶åˆ° 5 åˆ†é’Ÿ
    )
    
    # æ£€æŸ¥å“åº”
    if response.status_code != 200:
        error_msg = f"Google API é”™è¯¯ [{response.status_code}]: {response.text}"
        raise Exception(error_msg)
    
    # è§£æå“åº”
    result = response.json()
    
    # ğŸŒ æ£€æµ‹å®é™…ä½¿ç”¨çš„è¯­è¨€ï¼ˆå¦‚æœ Google API è¿”å›äº† languageCodeï¼‰
    detected_language = None
    if "results" in result and len(result["results"]) > 0:
        detected_language = result["results"][0].get("languageCode")
        if detected_language:
            print(f"[v110-GOOGLE] ğŸŒ æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_language}")
    
    # ğŸ™ï¸ v110: å¤„ç†å¤šè¯´è¯äººåˆ†ç¦»ç»“æœ
    if enable_diarization and "results" in result:
        print(f"[v110-DIARIZATION] å¼€å§‹å¤„ç†å¤šè¯´è¯äººè½¬å½•ç»“æœ")
        text = parse_diarization_result(result)
        speaker_count = count_unique_speakers(result)
        print(f"[v110-DIARIZATION] âœ… æ£€æµ‹åˆ° {speaker_count} ä¸ªè¯´è¯äºº")
    else:
        # æ ‡å‡†è½¬å½•ï¼ˆæ— è¯´è¯äººåˆ†ç¦»ï¼‰
        text = ""
        if "results" in result and len(result["results"]) > 0:
            for r in result["results"]:
                if "alternatives" in r and len(r["alternatives"]) > 0:
                    text += r["alternatives"][0].get("transcript", "")
    
    if not text:
        raise Exception("Google API è¿”å›ç©ºæ–‡æœ¬")
    
    metadata = {
        "api": "google",
        "model": "default",
        "status_code": response.status_code,
        "diarization_enabled": enable_diarization,
        "detected_language": detected_language  # ğŸŒ æ·»åŠ æ£€æµ‹åˆ°çš„è¯­è¨€
    }
    
    if enable_diarization:
        metadata["speaker_count"] = count_unique_speakers(result)
    
    return text, metadata


# ================================================================================
# æ ¸å¿ƒ Fallback å‡½æ•°
# ================================================================================

async def transcribe_with_fallback(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, str, Dict[str, Any]]:
    """
    ğŸ¤ v111: éº¦å…‹é£åœºæ™¯æ™ºèƒ½ fallback è½¬å½•
    
    ä¼˜å…ˆçº§ï¼š
    1ï¸âƒ£ Deepgram Nova-3 Multilingual
    2ï¸âƒ£ AI Builder Space (OpenAI Whisper)
    3ï¸âƒ£ OpenAI Whisper API
    
    Args:
        audio_content: éŸ³é¢‘æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
        filename: æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼Œå¯é€‰ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        Tuple[str, str, dict]: (è½¬å½•æ–‡æœ¬, ä½¿ç”¨çš„API, å…ƒæ•°æ®)
    """
    errors = []
    
    # ============================================================================
    # ğŸ†• v111: 1ï¸âƒ£ å°è¯• Deepgram Nova-3 Multilingualï¼ˆä¸»åŠ›ï¼‰
    # ============================================================================
    if should_retry_api("deepgram"):
        try:
            text, metadata = await _transcribe_deepgram(
                audio_content, filename, language, duration, 
                enable_diarization=False,  # éº¦å…‹é£åœºæ™¯ä¸éœ€è¦å¤šè¯´è¯äººè¯†åˆ«
                logger=logger
            )
            
            print(f"[v111-FALLBACK] âœ… Deepgram Nova-3 è½¬å½•æˆåŠŸ")
            return text, "deepgram_nova3_multilingual", metadata
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"Deepgram: {error_msg}")
            print(f"[v111-FALLBACK] âŒ Deepgram å¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if is_quota_exceeded(None, error_msg):
                API_FALLBACK_STATUS["deepgram_quota_exceeded"] = True
                API_FALLBACK_STATUS["deepgram_last_check"] = time.time()
                print(f"[v111-FALLBACK] ğŸš¨ Deepgram é…é¢è€—å°½ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª API")
    else:
        print(f"[v111-FALLBACK] â­ï¸ è·³è¿‡ Deepgramï¼ˆé…é¢å·²è€—å°½ï¼‰")
        errors.append("Deepgram: é…é¢å·²è€—å°½ï¼Œè·³è¿‡")
    
    # ============================================================================
    # 2ï¸âƒ£ å°è¯• AI Builder Space
    # ============================================================================
    if should_retry_api("ai_builder"):
        try:
            text, metadata = await _transcribe_ai_builder(
                audio_content, filename, language, duration, logger
            )
            
            print(f"[v111-FALLBACK] âœ… AI Builder Space è½¬å½•æˆåŠŸ (Fallback #2)")
            return text, "ai_builder", metadata
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"AI Builder: {error_msg}")
            print(f"[v111-FALLBACK] âŒ AI Builder å¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if is_quota_exceeded(None, error_msg):
                API_FALLBACK_STATUS["ai_builder_quota_exceeded"] = True
                API_FALLBACK_STATUS["ai_builder_last_check"] = time.time()
                print(f"[v111-FALLBACK] ğŸš¨ AI Builder é…é¢è€—å°½ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª API")
    else:
        print(f"[v111-FALLBACK] â­ï¸ è·³è¿‡ AI Builderï¼ˆé…é¢å·²è€—å°½ï¼‰")
        errors.append("AI Builder: é…é¢å·²è€—å°½ï¼Œè·³è¿‡")
    
    # ============================================================================
    # 3ï¸âƒ£ å°è¯• OpenAI Whisper APIï¼ˆæœ€åæ‰‹æ®µï¼‰
    # ============================================================================
    if should_retry_api("openai"):
        try:
            text, metadata = await _transcribe_openai(
                audio_content, filename, language, duration, logger
            )
            
            print(f"[v111-FALLBACK] âœ… OpenAI Whisper è½¬å½•æˆåŠŸ (Fallback #3 - æœ€åæ‰‹æ®µ)")
            return text, "openai_whisper", metadata
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"OpenAI: {error_msg}")
            print(f"[v111-FALLBACK] âŒ OpenAI Whisper å¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if is_quota_exceeded(None, error_msg):
                API_FALLBACK_STATUS["openai_quota_exceeded"] = True
                API_FALLBACK_STATUS["openai_last_check"] = time.time()
    else:
        print(f"[v111-FALLBACK] â­ï¸ è·³è¿‡ OpenAIï¼ˆé…é¢å·²è€—å°½ï¼‰")
        errors.append("OpenAI: é…é¢å·²è€—å°½ï¼Œè·³è¿‡")
    
    # ============================================================================
    # âŒ æ‰€æœ‰ API éƒ½å¤±è´¥
    # ============================================================================
    error_summary = " | ".join(errors)
    print(f"[v111-FALLBACK] ğŸ’¥ æ‰€æœ‰ API éƒ½å¤±è´¥äº†")
    print(f"[v111-FALLBACK] é”™è¯¯æ±‡æ€»: {error_summary}")
    
    raise Exception(f"æ‰€æœ‰è½¬å½• API éƒ½å¤±è´¥äº†: {error_summary}")


# ================================================================================
# ğŸ†• v111: ç³»ç»Ÿ/æ··åˆéŸ³é¢‘ä¸“ç”¨å‡½æ•°ï¼ˆDeepgram + Google åŒä¿é™©ï¼‰
# ================================================================================

async def transcribe_system_audio(
    audio_content: bytes,
    filename: str,
    language: Optional[str] = None,
    duration: Optional[int] = None,
    logger: Optional[TranscriptionLogger] = None
) -> Tuple[str, str, Dict[str, Any]]:
    """
    ğŸ”Š v111: ç³»ç»Ÿ/æ··åˆéŸ³é¢‘è½¬å½•ï¼ˆæ”¯æŒå¤šè¯´è¯äººè¯†åˆ«ï¼‰
    
    ä¼˜å…ˆçº§ï¼š
    1ï¸âƒ£ Deepgram Nova-3 Multilingual + Diarization
    2ï¸âƒ£ Google Cloud Speech-to-Text + Diarization
    
    Args:
        audio_content: éŸ³é¢‘æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
        filename: æ–‡ä»¶å
        language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼Œå¯é€‰ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        Tuple[str, str, dict]: (è½¬å½•æ–‡æœ¬, ä½¿ç”¨çš„API, å…ƒæ•°æ®)
    """
    print(f"[v111-SYSTEM] ğŸ”Š ç³»ç»Ÿ/æ··åˆéŸ³é¢‘åœºæ™¯ â†’ å¯ç”¨å¤šè¯´è¯äººè¯†åˆ«")
    errors = []
    
    # ============================================================================
    # 1ï¸âƒ£ å°è¯• Deepgram Nova-3 Multilingual + Diarization
    # ============================================================================
    if should_retry_api("deepgram"):
        try:
            text, metadata = await _transcribe_deepgram(
                audio_content=audio_content,
                filename=filename,
                language=language,
                duration=duration,
                enable_diarization=True,  # ğŸ¤ å¯ç”¨å¤šè¯´è¯äººè¯†åˆ«
                logger=logger
            )
            
            # æˆåŠŸï¼æ›´æ–°çŠ¶æ€
            API_FALLBACK_STATUS["last_successful_api"] = "deepgram"
            API_FALLBACK_STATUS["api_usage_count"]["deepgram"] += 1
            
            print(f"[v111-SYSTEM] âœ… Deepgram Nova-3 è½¬å½•æˆåŠŸï¼ˆå¤šè¯´è¯äººï¼‰")
            
            return text, "deepgram_nova3_multilingual", metadata
            
        except Exception as e:
            error_msg = str(e)
            errors.append(f"Deepgram: {error_msg}")
            print(f"[v111-SYSTEM] âŒ Deepgram å¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é—®é¢˜
            if is_quota_exceeded(None, error_msg):
                API_FALLBACK_STATUS["deepgram_quota_exceeded"] = True
                API_FALLBACK_STATUS["deepgram_last_check"] = time.time()
                print(f"[v111-SYSTEM] ğŸš¨ Deepgram é…é¢è€—å°½ï¼Œåˆ‡æ¢åˆ° Google")
    else:
        print(f"[v111-SYSTEM] â­ï¸ è·³è¿‡ Deepgramï¼ˆé…é¢å·²è€—å°½ï¼‰")
        errors.append("Deepgram: é…é¢å·²è€—å°½ï¼Œè·³è¿‡")
    
    # ============================================================================
    # 2ï¸âƒ£ å°è¯• Google Cloud Speech-to-Text + Diarization
    # ============================================================================
    try:
        text, metadata = await _transcribe_google(
            audio_content=audio_content,
            filename=filename,
            language=language,
            duration=duration,
            enable_diarization=True,  # ğŸ¤ å¯ç”¨å¤šè¯´è¯äººè¯†åˆ«
            logger=logger
        )
        
        # æˆåŠŸï¼æ›´æ–°çŠ¶æ€
        API_FALLBACK_STATUS["last_successful_api"] = "google"
        API_FALLBACK_STATUS["api_usage_count"]["google"] += 1
        
        print(f"[v111-SYSTEM] âœ… Google API è½¬å½•æˆåŠŸï¼ˆå¤šè¯´è¯äººï¼‰")
        
        return text, "google", metadata
        
    except Exception as e:
        error_msg = str(e)
        errors.append(f"Google: {error_msg}")
        
        if logger:
            logger.log_error("API_SYSTEM_ALL_FAILED", f"ç³»ç»ŸéŸ³é¢‘ API å…¨éƒ¨å¤±è´¥")
        
        print(f"[v111-SYSTEM] âŒ Google API å¤±è´¥: {error_msg}")
    
    # ============================================================================
    # âŒ æ‰€æœ‰ API éƒ½å¤±è´¥
    # ============================================================================
    error_summary = " | ".join(errors)
    print(f"[v111-SYSTEM] ğŸ’¥ æ‰€æœ‰ç³»ç»ŸéŸ³é¢‘ API éƒ½å¤±è´¥äº†")
    print(f"[v111-SYSTEM] é”™è¯¯æ±‡æ€»: {error_summary}")
    
    raise Exception(f"ç³»ç»ŸéŸ³é¢‘è½¬å½•å¤±è´¥ï¼ˆæ‰€æœ‰ APIï¼‰: {error_summary}")


# ================================================================================
# çŠ¶æ€æŸ¥è¯¢å‡½æ•°
# ================================================================================

def get_api_status() -> Dict[str, Any]:
    """
    è·å–å½“å‰ API fallback çŠ¶æ€
    
    Returns:
        dict: API çŠ¶æ€ä¿¡æ¯
    """
    return {
        "deepgram": {  # ğŸ†• v111
            "available": not API_FALLBACK_STATUS["deepgram_quota_exceeded"],
            "quota_exceeded": API_FALLBACK_STATUS["deepgram_quota_exceeded"],
            "last_check": API_FALLBACK_STATUS["deepgram_last_check"],
            "usage_count": API_FALLBACK_STATUS["api_usage_count"]["deepgram"]
        },
        "ai_builder": {
            "available": not API_FALLBACK_STATUS["ai_builder_quota_exceeded"],
            "quota_exceeded": API_FALLBACK_STATUS["ai_builder_quota_exceeded"],
            "last_check": API_FALLBACK_STATUS["ai_builder_last_check"],
            "usage_count": API_FALLBACK_STATUS["api_usage_count"]["ai_builder"]
        },
        "openai": {
            "available": not API_FALLBACK_STATUS["openai_quota_exceeded"],
            "quota_exceeded": API_FALLBACK_STATUS["openai_quota_exceeded"],
            "last_check": API_FALLBACK_STATUS["openai_last_check"],
            "usage_count": API_FALLBACK_STATUS["api_usage_count"]["openai"]
        },
        "google": {
            "available": True,
            "usage_count": API_FALLBACK_STATUS["api_usage_count"]["google"]
        },
        "last_successful_api": API_FALLBACK_STATUS["last_successful_api"]
    }
