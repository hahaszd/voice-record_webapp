// å…¨å±€å˜é‡
let mediaRecorder = null;
let isRecording = false;
let recordingStartTime = null;
let recordingTimer = null;
let recordedMimeType = 'audio/webm;codecs=opus';
let maxRecordingDuration = 10000; // 10ç§’
let cleanupTimer = null; // å®šæœŸæ¸…ç†å®šæ—¶å™¨

// åˆå§‹åŒ–
document.addEventListener('DOMContentLoaded', async () => {
    // åˆå§‹åŒ–IndexedDBå­˜å‚¨
    try {
        await audioStorage.init();
        console.log('[INFO] IndexedDBå­˜å‚¨åˆå§‹åŒ–æˆåŠŸ');
    } catch (error) {
        console.error('[ERROR] IndexedDBåˆå§‹åŒ–å¤±è´¥:', error);
        alert('æµè§ˆå™¨å­˜å‚¨åˆå§‹åŒ–å¤±è´¥ï¼Œå½•éŸ³åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸ä½¿ç”¨');
    }

    const recordBtn = document.getElementById('recordBtn');
    const recordBtnText = document.getElementById('recordBtnText');
    const recordingStatus = document.getElementById('recordingStatus');
    const recordingTime = document.getElementById('recordingTime');
    const transcribeOptions = document.getElementById('transcribeOptions');
    const transcribeLast10Btn = document.getElementById('transcribeLast10Btn');
    const audioPlayer = document.getElementById('audioPlayer');
    const resultSection = document.getElementById('resultSection');
    const transcriptionResult = document.getElementById('transcriptionResult');
    const copyBtn = document.getElementById('copyBtn');
    const loadingIndicator = document.getElementById('loadingIndicator');

    // å½•éŸ³æŒ‰é’®ç‚¹å‡»äº‹ä»¶
    recordBtn.addEventListener('click', async () => {
        if (!isRecording) {
            await startRecording();
        } else {
            await stopRecording();
        }
    });

    // è½¬å½•æœ€å10ç§’æŒ‰é’®ç‚¹å‡»äº‹ä»¶
    transcribeLast10Btn.addEventListener('click', async () => {
        await transcribeLast10Seconds();
    });

    // å¤åˆ¶æŒ‰é’®ç‚¹å‡»äº‹ä»¶
    copyBtn.addEventListener('click', () => {
        const text = transcriptionResult.value;
        if (text) {
            navigator.clipboard.writeText(text).then(() => {
                copyBtn.innerHTML = '<span>âœ“</span> å·²å¤åˆ¶';
                setTimeout(() => {
                    copyBtn.innerHTML = '<span>ğŸ“‹</span> å¤åˆ¶';
                }, 2000);
            }).catch(err => {
                console.error('å¤åˆ¶å¤±è´¥:', err);
                transcriptionResult.select();
                document.execCommand('copy');
                copyBtn.innerHTML = '<span>âœ“</span> å·²å¤åˆ¶';
                setTimeout(() => {
                    copyBtn.innerHTML = '<span>ğŸ“‹</span> å¤åˆ¶';
                }, 2000);
            });
        }
    });

    // å¼€å§‹å½•éŸ³
    async function startRecording() {
        try {
            // æ¸…ç©ºä¹‹å‰çš„å½•éŸ³æ•°æ®
            await audioStorage.clearAll();
            
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            
            // ä½¿ç”¨ MediaRecorder API
            const options = {
                mimeType: 'audio/webm;codecs=opus'
            };
            
            // å¦‚æœä¸æ”¯æŒ webmï¼Œå°è¯•å…¶ä»–æ ¼å¼
            if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                options.mimeType = 'audio/webm';
                if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                    options.mimeType = 'audio/mp4';
                }
            }
            
            mediaRecorder = new MediaRecorder(stream, options);
            recordedMimeType = options.mimeType;
            
            console.log('[INFO] å¼€å§‹å½•éŸ³ï¼Œä½¿ç”¨MIMEç±»å‹:', recordedMimeType);
            
            // æ•°æ®å¯ç”¨äº‹ä»¶ï¼šä¿å­˜åˆ°IndexedDB
            mediaRecorder.ondataavailable = async (event) => {
                if (event.data.size > 0) {
                    const currentTime = Date.now();
                    const elapsed = currentTime - recordingStartTime;
                    const chunkTimestamp = elapsed;
                    
                    // ä¿å­˜chunkåˆ°IndexedDB
                    try {
                        await audioStorage.saveChunk(event.data, chunkTimestamp);
                        console.log(`[INFO] ä¿å­˜éŸ³é¢‘chunk: ${(chunkTimestamp/1000).toFixed(2)}ç§’`);
                    } catch (error) {
                        console.error('[ERROR] ä¿å­˜chunkå¤±è´¥:', error);
                    }
                }
            };
            
            mediaRecorder.onstop = () => {
                stream.getTracks().forEach(track => track.stop());
            };
            
            // æ¯1ç§’ä¿å­˜ä¸€æ¬¡æ•°æ®
            mediaRecorder.start(1000);
            
            isRecording = true;
            recordingStartTime = Date.now();
            
            // å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡ï¼ˆæ¯30ç§’æ¸…ç†ä¸€æ¬¡ï¼‰
            audioStorage.startCleanupTimer(recordingStartTime);
            
            // æ›´æ–°UI
            recordBtn.classList.add('recording');
            recordBtnText.textContent = 'åœæ­¢å½•éŸ³';
            recordingStatus.textContent = 'æ­£åœ¨å½•éŸ³ä¸­...';
            transcribeOptions.style.display = 'none';
            resultSection.style.display = 'none';
            
            // æ›´æ–°å½•éŸ³æ—¶é—´
            recordingTimer = setInterval(() => {
                const elapsed = Date.now() - recordingStartTime;
                const seconds = Math.floor(elapsed / 1000);
                const minutes = Math.floor(seconds / 60);
                const displaySeconds = seconds % 60;
                recordingTime.textContent = `${String(minutes).padStart(2, '0')}:${String(displaySeconds).padStart(2, '0')}`;
                
                // å¦‚æœè¶…è¿‡10ç§’ï¼Œæ˜¾ç¤ºæç¤º
                if (elapsed > maxRecordingDuration) {
                    recordingStatus.textContent = 'å½•éŸ³ä¸­ï¼ˆä»…ä¿ç•™æœ€å10ç§’ï¼‰...';
                }
            }, 100);
            
        } catch (error) {
            console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
            alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
        }
    }

    // åœæ­¢å½•éŸ³
    async function stopRecording() {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
        }
        
        isRecording = false;
        clearInterval(recordingTimer);
        
        // åœæ­¢å®šæœŸæ¸…ç†ä»»åŠ¡
        audioStorage.stopCleanupTimer();
        
        // æ‰§è¡Œæœ€åä¸€æ¬¡æ¸…ç†ï¼Œç¡®ä¿åªä¿ç•™æœ€å10ç§’
        const currentTime = Date.now();
        await audioStorage.cleanupOldChunks(currentTime);
        
        // è·å–å­˜å‚¨çš„æ•°æ®å¤§å°
        const storageSize = await audioStorage.getStorageSize();
        
        const elapsed = Date.now() - recordingStartTime;
        console.log(`[INFO] å½•éŸ³åœæ­¢:`);
        console.log(`  - æ€»å½•éŸ³æ—¶é•¿: ${(elapsed / 1000).toFixed(2)}ç§’`);
        console.log(`  - å­˜å‚¨çš„æ•°æ®å¤§å°: ${(storageSize / 1024).toFixed(2)} KB`);
        
        // æ›´æ–°UI
        recordBtn.classList.remove('recording');
        recordBtnText.textContent = 'å¼€å§‹å½•éŸ³';
        recordingStatus.textContent = 'å½•éŸ³å·²åœæ­¢';
        transcribeOptions.style.display = 'block';
    }

    // è½¬å½•æœ€å10ç§’
    async function transcribeLast10Seconds() {
        const startTime = Date.now();
        console.log(`\n${'='.repeat(80)}`);
        console.log(`[INFO] å¼€å§‹è½¬å½•æœ€å10ç§’`);
        console.log(`${'='.repeat(80)}\n`);
        
        loadingIndicator.style.display = 'block';
        resultSection.style.display = 'block';
        transcriptionResult.value = '';
        
        try {
            // ä»IndexedDBè·å–æ‰€æœ‰chunks
            const { chunks, timestamps } = await audioStorage.getAllChunks();
            
            if (chunks.length === 0) {
                alert('æ²¡æœ‰å¯ç”¨çš„éŸ³é¢‘æ•°æ®');
                loadingIndicator.style.display = 'none';
                return;
            }
            
            console.log(`[INFO] ä»IndexedDBè·å–åˆ° ${chunks.length} ä¸ªéŸ³é¢‘å—`);
            
            // åˆ›å»ºå®Œæ•´çš„éŸ³é¢‘blob
            const fullAudioBlob = new Blob(chunks, { type: recordedMimeType });
            console.log(`[INFO] å®Œæ•´éŸ³é¢‘ Blob:`);
            console.log(`  - å¤§å°: ${(fullAudioBlob.size / 1024).toFixed(2)} KB`);
            console.log(`  - ç±»å‹: ${fullAudioBlob.type}`);
            
            // è®¡ç®—å®é™…å½•éŸ³æ—¶é•¿
            const actualDuration = timestamps.length > 0 
                ? (Math.max(...timestamps) - Math.min(...timestamps)) / 1000
                : 0;
            
            console.log(`[INFO] å®é™…å½•éŸ³æ—¶é•¿: ${actualDuration.toFixed(2)}ç§’`);
            
            // ç”Ÿæˆå¯æ’­æ”¾çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆæå–æœ€å10ç§’ï¼‰
            let audioBlobToPlay;
            let audioBlobToTranscribe;
            
            if (actualDuration > 10) {
                console.log(`[INFO] å½•éŸ³æ—¶é•¿è¶…è¿‡10ç§’ï¼Œæå–æœ€å10ç§’`);
                try {
                    // ä½¿ç”¨Web Audio APIæå–æœ€å10ç§’
                    audioBlobToPlay = await extractAudioSegment(fullAudioBlob, 10);
                    audioBlobToTranscribe = audioBlobToPlay;
                    console.log(`[INFO] âœ… æˆåŠŸæå–æœ€å10ç§’éŸ³é¢‘`);
                } catch (extractError) {
                    console.error('[ERROR] æå–æœ€å10ç§’å¤±è´¥:', extractError);
                    // å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘ï¼Œæ ‡è®°éœ€è¦æœåŠ¡å™¨ç«¯æˆªå–
                    audioBlobToPlay = fullAudioBlob;
                    audioBlobToTranscribe = fullAudioBlob;
                }
            } else {
                // å½•éŸ³ä¸è¶…è¿‡10ç§’ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´éŸ³é¢‘
                audioBlobToPlay = fullAudioBlob;
                audioBlobToTranscribe = fullAudioBlob;
            }
            
            // æ˜¾ç¤ºå¯æ’­æ”¾çš„éŸ³é¢‘æ–‡ä»¶
            const audioUrl = URL.createObjectURL(audioBlobToPlay);
            audioPlayer.src = audioUrl;
            audioPlayer.style.display = 'block';
            console.log(`[INFO] âœ… ç”Ÿæˆå¯æ’­æ”¾çš„éŸ³é¢‘æ–‡ä»¶`);
            
            // å‘é€åˆ°æœåŠ¡å™¨è¿›è¡Œè½¬å½•
            const formData = new FormData();
            const extension = audioBlobToTranscribe.type.includes('webm') ? 'webm' : 
                             audioBlobToTranscribe.type.includes('wav') ? 'wav' : 
                             audioBlobToTranscribe.type.includes('mp3') ? 'mp3' : 'mp4';
            const filename = `recording_last10s.${extension}`;
            
            formData.append('audio_file', audioBlobToTranscribe, filename);
            formData.append('duration', '10');
            
            // å¦‚æœå½•éŸ³è¶…è¿‡10ç§’ï¼Œæ ‡è®°éœ€è¦æœåŠ¡å™¨ç«¯æˆªå–
            if (actualDuration > 10) {
                formData.append('needs_segmentation', 'true');
                console.log(`[INFO] æ ‡è®°ï¼šéœ€è¦æœåŠ¡å™¨ç«¯æˆªå–æœ€å10ç§’`);
            }
            
            // å‘é€åˆ°æœåŠ¡å™¨
            console.log(`[INFO] å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨...`);
            const requestStartTime = Date.now();
            const response = await fetch('/transcribe-segment', {
                method: 'POST',
                body: formData
            });
            const requestEndTime = Date.now();
            const requestDuration = (requestEndTime - requestStartTime) / 1000;
            
            console.log(`[INFO] æœåŠ¡å™¨å“åº”:`);
            console.log(`  - çŠ¶æ€ç : ${response.status}`);
            console.log(`  - è¯·æ±‚è€—æ—¶: ${requestDuration.toFixed(2)}ç§’`);
            
            if (!response.ok) {
                const errorText = await response.text();
                console.error(`[ERROR] HTTP é”™è¯¯å“åº”:`, errorText.substring(0, 500));
                throw new Error(`HTTP error! status: ${response.status}, message: ${errorText.substring(0, 200)}`);
            }
            
            const result = await response.json();
            console.log(`[INFO] è§£æåçš„å“åº”:`);
            console.log(`  - Success: ${result.success}`);
            console.log(`  - Message: ${result.message || 'N/A'}`);
            console.log(`  - Text length: ${result.text ? result.text.length : 0}`);
            
            if (result.success) {
                transcriptionResult.value = result.text || 'æœªè¯†åˆ«åˆ°æ–‡å­—';
                console.log(`[SUCCESS] è½¬å½•å®Œæˆ`);
            } else {
                let errorMsg = `é”™è¯¯: ${result.message || 'è½¬å½•å¤±è´¥'}`;
                transcriptionResult.value = errorMsg;
                console.error(`[ERROR] è½¬å½•å¤±è´¥: ${result.message}`);
            }
            
            const totalDuration = (Date.now() - startTime) / 1000;
            console.log(`\n${'='.repeat(80)}`);
            console.log(`[INFO] è½¬å½•æµç¨‹å®Œæˆ - æ€»è€—æ—¶: ${totalDuration.toFixed(2)}ç§’`);
            console.log(`${'='.repeat(80)}\n`);
            
        } catch (error) {
            console.error(`\n${'='.repeat(80)}`);
            console.error(`[EXCEPTION] è½¬å½•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸`);
            console.error(`  - é”™è¯¯ç±»å‹: ${error.name}`);
            console.error(`  - é”™è¯¯æ¶ˆæ¯: ${error.message}`);
            console.error(`  - é”™è¯¯å †æ ˆ:`, error.stack);
            console.error(`${'='.repeat(80)}\n`);
            transcriptionResult.value = `é”™è¯¯: ${error.message}`;
        } finally {
            loadingIndicator.style.display = 'none';
        }
    }

    // æå–éŸ³é¢‘ç‰‡æ®µï¼ˆæœ€åNç§’ï¼‰
    async function extractAudioSegment(audioBlob, durationSeconds) {
        try {
            console.log(`å¼€å§‹æå–æœ€å ${durationSeconds} ç§’çš„éŸ³é¢‘...`);
            
            // ä½¿ç”¨ Web Audio API å¤„ç†éŸ³é¢‘
            const arrayBuffer = await audioBlob.arrayBuffer();
            console.log(`éŸ³é¢‘æ–‡ä»¶å¤§å°: ${(arrayBuffer.byteLength / 1024).toFixed(2)} KB`);
            
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            
            // å°è¯•è§£ç éŸ³é¢‘æ•°æ®
            let audioBuffer;
            try {
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer.slice(0));
            } catch (decodeError) {
                console.warn(`Web Audio API è§£ç å¤±è´¥: ${decodeError.name} - ${decodeError.message}`);
                console.warn(`å°è¯•ä½¿ç”¨æ›¿ä»£æ–¹æ³•...`);
                audioContext.close();
                // å¦‚æœè§£ç å¤±è´¥ï¼Œè¿”å›åŸå§‹éŸ³é¢‘
                return audioBlob;
            }
            
            const sampleRate = audioBuffer.sampleRate;
            const channels = audioBuffer.numberOfChannels;
            const totalSamples = audioBuffer.length;
            const totalDuration = totalSamples / sampleRate;
            const targetSamples = sampleRate * durationSeconds;
            
            console.log(`éŸ³é¢‘ä¿¡æ¯: é‡‡æ ·ç‡=${sampleRate}Hz, å£°é“æ•°=${channels}, æ€»æ—¶é•¿=${totalDuration.toFixed(2)}ç§’`);
            
            // å¦‚æœéŸ³é¢‘æ—¶é•¿å°äºè¯·æ±‚çš„æ—¶é•¿ï¼Œè¿”å›å®Œæ•´éŸ³é¢‘
            if (totalDuration <= durationSeconds) {
                console.log(`éŸ³é¢‘æ—¶é•¿ (${totalDuration.toFixed(2)}ç§’) å°äºç­‰äºè¯·æ±‚æ—¶é•¿ (${durationSeconds}ç§’)ï¼Œè¿”å›å®Œæ•´éŸ³é¢‘`);
                audioContext.close();
                return audioBlob;
            }
            
            // è·å–æœ€åNç§’çš„æ•°æ®
            const startSample = Math.max(0, totalSamples - targetSamples);
            const segmentLength = totalSamples - startSample;
            const actualDuration = segmentLength / sampleRate;
            
            console.log(`æå–ç‰‡æ®µ: èµ·å§‹æ ·æœ¬=${startSample}, é•¿åº¦=${segmentLength}, å®é™…æ—¶é•¿=${actualDuration.toFixed(2)}ç§’`);
            
            // åˆ›å»ºæ–°çš„ AudioBuffer
            const segmentBuffer = audioContext.createBuffer(channels, segmentLength, sampleRate);
            
            for (let channel = 0; channel < channels; channel++) {
                const originalData = audioBuffer.getChannelData(channel);
                const segmentData = segmentBuffer.getChannelData(channel);
                segmentData.set(originalData.subarray(startSample));
            }
            
            // è½¬æ¢ä¸º WAV
            const wavBlob = audioBufferToWav(segmentBuffer);
            console.log(`WAV æ–‡ä»¶å¤§å°: ${(wavBlob.size / 1024).toFixed(2)} KB`);
            
            audioContext.close();
            
            return wavBlob;
            
        } catch (error) {
            console.error('æå–éŸ³é¢‘ç‰‡æ®µå¤±è´¥:', error);
            console.error('é”™è¯¯ç±»å‹:', error.name);
            console.error('é”™è¯¯æ¶ˆæ¯:', error.message);
            console.error('é”™è¯¯å †æ ˆ:', error.stack);
            console.warn('å°†ä½¿ç”¨å®Œæ•´éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè½¬å½•');
            return audioBlob; // å¦‚æœå¤±è´¥ï¼Œè¿”å›åŸå§‹blob
        }
    }

    // AudioBuffer è½¬ WAV Blob
    function audioBufferToWav(buffer) {
        const length = buffer.length;
        const sampleRate = buffer.sampleRate;
        const channels = buffer.numberOfChannels;
        const bytesPerSample = 2; // 16-bit
        const blockAlign = channels * bytesPerSample;
        const dataSize = length * blockAlign;
        const arrayBuffer = new ArrayBuffer(44 + dataSize);
        const view = new DataView(arrayBuffer);
        
        // WAV æ–‡ä»¶å¤´
        const writeString = (offset, string) => {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        };
        
        // RIFF header
        writeString(0, 'RIFF');
        view.setUint32(4, 36 + dataSize, true); // File size - 8
        writeString(8, 'WAVE');
        
        // fmt chunk
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true); // fmt chunk size
        view.setUint16(20, 1, true); // Audio format (1 = PCM)
        view.setUint16(22, channels, true); // Number of channels
        view.setUint32(24, sampleRate, true); // Sample rate
        view.setUint32(28, sampleRate * blockAlign, true); // Byte rate
        view.setUint16(32, blockAlign, true); // Block align
        view.setUint16(34, 16, true); // Bits per sample
        
        // data chunk
        writeString(36, 'data');
        view.setUint32(40, dataSize, true); // Data size
        
        // å†™å…¥éŸ³é¢‘æ•°æ®ï¼ˆäº¤é”™æ ¼å¼ï¼šL, R, L, R, ...ï¼‰
        let offset = 44;
        for (let i = 0; i < length; i++) {
            for (let channel = 0; channel < channels; channel++) {
                const channelData = buffer.getChannelData(channel);
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                const int16Sample = sample < 0 
                    ? Math.max(-32768, Math.round(sample * 0x8000))
                    : Math.min(32767, Math.round(sample * 0x7FFF));
                view.setInt16(offset, int16Sample, true);
                offset += 2;
            }
        }
        
        return new Blob([arrayBuffer], { type: 'audio/wav' });
    }
});
